2025-10-15 19:51:07,819 - app.main - INFO - Starting Understudy API...
2025-10-15 19:51:07,827 - app.main - INFO - Database initialized
2025-10-15 19:51:49,025 - app.providers.factory - ERROR - Failed to create provider openai: OpenAI API key not provided
2025-10-15 19:51:49,026 - app.api.endpoints - ERROR - Inference error: OpenAI API key not provided
2025-10-15 19:54:05,475 - app.main - INFO - Starting Understudy API...
2025-10-15 19:54:28,712 - app.main - INFO - Starting Understudy API...
2025-10-15 19:54:28,723 - app.main - INFO - Database initialized
2025-10-15 19:55:17,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:29,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:30,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:31,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:32,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:34,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:57:34,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-18 19:23:59,509 - app.main - INFO - Starting Understudy API...
2025-10-18 19:23:59,555 - app.main - INFO - Database initialized
2025-10-18 19:23:59,631 - app.main - INFO - Initializing GPU training queue...
2025-10-18 19:23:59,632 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-18 19:23:59,643 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-18 19:23:59,644 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-18 19:23:59,645 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-18 19:23:59,646 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-18 19:23:59,646 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-18 19:23:59,775 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-18 19:23:59,777 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-18 19:24:00,438 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 19:24:00,441 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 19:24:00,962 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-18 19:24:00,978 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-18 19:24:00,985 - app.main - INFO - Initializing Lambda Cloud GPU training...
2025-10-18 19:24:01,010 - app.training.lambda_cloud_provisioner - INFO - Initializing Lambda Cloud infrastructure...
2025-10-18 19:24:01,013 - app.training.lambda_cloud_provisioner - INFO - Created new Lambda Cloud configuration
2025-10-18 19:24:01,014 - app.training.lambda_cloud_provisioner - INFO - Ensuring SSH key configuration...
2025-10-18 19:24:01,236 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 19:24:01,244 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 19:24:01,256 - app.training.lambda_cloud_provisioner - INFO - Checking available GPU instance types...
2025-10-18 19:24:01,701 - app.training.lambda_cloud_provisioner - INFO - Found 10 available GPU instance types
2025-10-18 19:24:01,706 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_gh200: 1x GH200 (96 GB) ($1.49/hr)
2025-10-18 19:24:01,711 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_b200_sxm6: 8x B200 (180 GB SXM6) ($39.92/hr)
2025-10-18 19:24:01,723 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_h100_sxm5: 8x H100 (80 GB SXM5) ($23.92/hr)
2025-10-18 19:24:01,725 - app.training.lambda_cloud_provisioner - INFO - Selected instance type: gpu_1x_gh200 (GH200 (96 GB)) at $1.49/hr
2025-10-18 19:24:01,749 - app.training.lambda_cloud_provisioner - INFO - Saved Lambda Cloud configuration
2025-10-18 19:24:01,750 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud infrastructure initialized successfully
2025-10-18 19:24:01,751 - app.main - INFO - Lambda Cloud GPU training initialized successfully
2025-10-18 19:24:01,752 - app.main - INFO - Cloud GPU training system ready
2025-10-18 19:25:02,083 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 19:26:40,479 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_192621 added to queue with priority 0
2025-10-18 19:26:41,009 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-18 19:26:41,032 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([])
2025-10-18 19:26:41,264 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 19:26:41,267 - app.training.lambda_cloud_trainer - INFO - Launching Lambda Cloud instance: lambda-gpu-20251018192641
2025-10-18 19:30:03,598 - app.training.lambda_cloud_trainer - INFO - Instance 02c5f5dbbb654ad9a3740cc78961d266 launched successfully at 192.222.58.211
2025-10-18 19:30:03,610 - app.training.gpu_queue_manager - INFO - Created new Lambda instance lambda-gpu-20251018192641
2025-10-18 19:30:03,639 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_192621 on lambda lambda-gpu-20251018192641
2025-10-18 19:30:03,642 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance 02c5f5dbbb654ad9a3740cc78961d266
2025-10-18 19:30:03,644 - app.training.lambda_cloud_trainer - ERROR - Training execution failed: name 'torch' is not defined
2025-10-18 19:30:03,646 - app.training.gpu_queue_manager - ERROR - Training failed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_192621: name 'torch' is not defined
2025-10-18 20:10:08,125 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 20:10:18,655 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201018 added to queue with priority 0
2025-10-18 20:10:19,493 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:10:19,502 - app.training.gpu_queue_manager - INFO - Removing terminated Lambda instance lambda-gpu-20251018192641
2025-10-18 20:10:19,506 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([])
2025-10-18 20:10:19,731 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:10:19,733 - app.training.lambda_cloud_trainer - INFO - Launching Lambda Cloud instance: lambda-gpu-20251018201019
2025-10-18 20:13:33,484 - app.training.lambda_cloud_trainer - INFO - Instance be45fe9c76dd42d6a595b8090e07cec1 launched successfully at 192.222.51.18
2025-10-18 20:13:33,505 - app.training.gpu_queue_manager - INFO - Created new Lambda instance lambda-gpu-20251018201019
2025-10-18 20:13:33,708 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201018 on lambda lambda-gpu-20251018201019
2025-10-18 20:13:33,715 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance be45fe9c76dd42d6a595b8090e07cec1
2025-10-18 20:13:33,718 - app.training.lambda_cloud_trainer - ERROR - Training execution failed: name 'torch' is not defined
2025-10-18 20:13:33,720 - app.training.gpu_queue_manager - ERROR - Training failed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201018: name 'torch' is not defined
2025-10-18 20:16:38,751 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 20:17:23,955 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201655 added to queue with priority 0
2025-10-18 20:17:24,631 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:17:24,644 - app.training.gpu_queue_manager - INFO - Removing terminated Lambda instance lambda-gpu-20251018201019
2025-10-18 20:18:00,229 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([])
2025-10-18 20:18:00,571 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:18:00,573 - app.training.lambda_cloud_trainer - INFO - Launching Lambda Cloud instance: lambda-gpu-20251018201800
2025-10-18 20:20:04,064 - app.training.lambda_cloud_trainer - INFO - Instance 13873712efae4a898ebbf5094c7b77a0 launched successfully at 192.222.57.28
2025-10-18 20:20:04,091 - app.training.gpu_queue_manager - INFO - Created new Lambda instance lambda-gpu-20251018201800
2025-10-18 20:20:04,106 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201655 on lambda lambda-gpu-20251018201800
2025-10-18 20:20:04,108 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:20:04,109 - app.training.lambda_cloud_trainer - ERROR - Training execution failed: name 'torch' is not defined
2025-10-18 20:20:04,110 - app.training.gpu_queue_manager - ERROR - Training failed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_201655: name 'torch' is not defined
2025-10-18 20:20:13,920 - app.main - INFO - Shutting down Understudy API...
2025-10-18 20:23:26,710 - app.main - INFO - Starting Understudy API...
2025-10-18 20:23:26,737 - app.main - INFO - Database initialized
2025-10-18 20:23:26,811 - app.main - INFO - Initializing GPU training queue...
2025-10-18 20:23:26,812 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-18 20:23:26,842 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-18 20:23:26,843 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-18 20:23:26,843 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-18 20:23:26,844 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-18 20:23:26,845 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-18 20:23:26,983 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-18 20:23:26,985 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-18 20:23:27,216 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:23:27,218 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:23:28,042 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:23:28,052 - app.training.gpu_queue_manager - INFO - Checking 1 existing Lambda instances for reuse eligibility
2025-10-18 20:23:28,065 - app.training.gpu_queue_manager - INFO - Instance: name='lambda-gpu-20251018201800', status='active', id='13873712efae4a898ebbf5094c7b77a0'
2025-10-18 20:23:28,069 - app.training.gpu_queue_manager - INFO - Instance SSH keys: ['understudy-key-v2']
2025-10-18 20:23:28,071 - app.training.gpu_queue_manager - INFO - Found existing Lambda instance: lambda-gpu-20251018201800 (13873712efae4a898ebbf5094c7b77a0)
2025-10-18 20:23:28,077 - app.training.gpu_queue_manager - INFO - Discovered 1 existing Lambda instances available for reuse
2025-10-18 20:23:28,094 - app.main - INFO - Initializing Lambda Cloud GPU training...
2025-10-18 20:23:28,152 - app.training.lambda_cloud_provisioner - INFO - Initializing Lambda Cloud infrastructure...
2025-10-18 20:23:28,162 - app.training.lambda_cloud_provisioner - INFO - Loaded Lambda Cloud configuration from file
2025-10-18 20:23:28,163 - app.training.lambda_cloud_provisioner - INFO - Ensuring SSH key configuration...
2025-10-18 20:23:28,379 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:23:28,382 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:23:28,383 - app.training.lambda_cloud_provisioner - INFO - Checking available GPU instance types...
2025-10-18 20:23:28,856 - app.training.lambda_cloud_provisioner - INFO - Found 7 available GPU instance types
2025-10-18 20:23:28,858 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_gh200: 1x GH200 (96 GB) ($1.49/hr)
2025-10-18 20:23:28,860 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_b200_sxm6: 8x B200 (180 GB SXM6) ($39.92/hr)
2025-10-18 20:23:28,862 - app.training.lambda_cloud_provisioner - INFO -   - gpu_2x_h100_sxm5: 2x H100 (80 GB SXM5) ($6.38/hr)
2025-10-18 20:23:28,864 - app.training.lambda_cloud_provisioner - INFO - Selected instance type: gpu_1x_gh200 (GH200 (96 GB)) at $1.49/hr
2025-10-18 20:23:29,008 - app.training.lambda_cloud_provisioner - INFO - Saved Lambda Cloud configuration
2025-10-18 20:23:29,201 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud infrastructure initialized successfully
2025-10-18 20:23:29,210 - app.main - INFO - Lambda Cloud GPU training initialized successfully
2025-10-18 20:23:29,217 - app.main - INFO - Cloud GPU training system ready
2025-10-18 20:24:14,691 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 20:24:33,288 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_202422 added to queue with priority 0
2025-10-18 20:24:34,097 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:26:44,554 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([('13873712efae4a898ebbf5094c7b77a0', {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': None, 'provider': 'lambda', 'status': 'idle', 'last_used': datetime.datetime(2025, 10, 18, 20, 23, 28, 71058), 'instance': {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': '192.222.57.28', 'private_ip': '172.26.132.108', 'status': 'active', 'ssh_key_names': ['understudy-key-v2'], 'file_system_names': [], 'region': {'name': 'us-east-3', 'description': 'Washington DC, USA'}, 'instance_type': {'name': 'gpu_1x_gh200', 'description': '1x GH200 (96 GB)', 'gpu_description': 'GH200 (96 GB)', 'price_cents_per_hour': 149, 'specs': {'vcpus': 64, 'memory_gib': 432, 'storage_gib': 4096, 'gpus': 1}}, 'hostname': '192-222-57-28', 'jupyter_token': '55ac7aa49a0c4d6ba29bf55214ba2a1c', 'jupyter_url': 'https://ad2f3f68cd1e4ba788d0490a345846b0-0.lambdaspaces.com/?token=55ac7aa49a0c4d6ba29bf55214ba2a1c', 'is_reserved': False, 'actions': {'migrate': {'available': True}, 'rebuild': {'available': True}, 'restart': {'available': True}, 'cold_reboot': {'available': True}, 'terminate': {'available': True}}, 'firewall_rulesets': []}})])
2025-10-18 20:26:50,096 - app.training.gpu_queue_manager - INFO - Reusing Lambda instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:27:10,350 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_202422 on lambda lambda-gpu-20251018201800
2025-10-18 20:28:35,699 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:28:51,849 - app.training.lambda_cloud_trainer - ERROR - Training execution failed: name 'torch' is not defined
2025-10-18 20:28:51,860 - app.training.gpu_queue_manager - ERROR - Training failed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_202422: name 'torch' is not defined
2025-10-18 20:29:58,177 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 20:30:08,527 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_203004 added to queue with priority 0
2025-10-18 20:30:09,062 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:32:57,623 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([('13873712efae4a898ebbf5094c7b77a0', {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': None, 'provider': 'lambda', 'status': 'idle', 'last_used': datetime.datetime(2025, 10, 18, 20, 28, 51, 910873), 'instance': {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': '192.222.57.28', 'private_ip': '172.26.132.108', 'status': 'active', 'ssh_key_names': ['understudy-key-v2'], 'file_system_names': [], 'region': {'name': 'us-east-3', 'description': 'Washington DC, USA'}, 'instance_type': {'name': 'gpu_1x_gh200', 'description': '1x GH200 (96 GB)', 'gpu_description': 'GH200 (96 GB)', 'price_cents_per_hour': 149, 'specs': {'vcpus': 64, 'memory_gib': 432, 'storage_gib': 4096, 'gpus': 1}}, 'hostname': '192-222-57-28', 'jupyter_token': '55ac7aa49a0c4d6ba29bf55214ba2a1c', 'jupyter_url': 'https://ad2f3f68cd1e4ba788d0490a345846b0-0.lambdaspaces.com/?token=55ac7aa49a0c4d6ba29bf55214ba2a1c', 'is_reserved': False, 'actions': {'migrate': {'available': True}, 'rebuild': {'available': True}, 'restart': {'available': True}, 'cold_reboot': {'available': True}, 'terminate': {'available': True}}, 'firewall_rulesets': []}})])
2025-10-18 20:32:57,644 - app.training.gpu_queue_manager - INFO - Reusing Lambda instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:32:57,706 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_203004 on lambda lambda-gpu-20251018201800
2025-10-18 20:32:57,707 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:46:01,152 - app.main - INFO - Starting Understudy API...
2025-10-18 20:46:01,188 - app.main - INFO - Database initialized
2025-10-18 20:46:01,256 - app.main - INFO - Initializing GPU training queue...
2025-10-18 20:46:01,257 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-18 20:46:01,268 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-18 20:46:01,269 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-18 20:46:01,270 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-18 20:46:01,270 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-18 20:46:01,271 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-18 20:46:01,390 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-18 20:46:01,393 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-18 20:46:01,635 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:46:01,637 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:46:02,243 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:46:02,248 - app.training.gpu_queue_manager - INFO - Checking 1 existing Lambda instances for reuse eligibility
2025-10-18 20:46:02,251 - app.training.gpu_queue_manager - INFO - Instance: name='lambda-gpu-20251018201800', status='active', id='13873712efae4a898ebbf5094c7b77a0'
2025-10-18 20:46:02,254 - app.training.gpu_queue_manager - INFO - Instance SSH keys: ['understudy-key-v2']
2025-10-18 20:46:02,260 - app.training.gpu_queue_manager - INFO - Found existing Lambda instance: lambda-gpu-20251018201800 (13873712efae4a898ebbf5094c7b77a0)
2025-10-18 20:46:02,261 - app.training.gpu_queue_manager - INFO - Discovered 1 existing Lambda instances available for reuse
2025-10-18 20:46:02,262 - app.main - INFO - Initializing Lambda Cloud GPU training...
2025-10-18 20:46:02,276 - app.training.lambda_cloud_provisioner - INFO - Initializing Lambda Cloud infrastructure...
2025-10-18 20:46:02,283 - app.training.lambda_cloud_provisioner - INFO - Loaded Lambda Cloud configuration from file
2025-10-18 20:46:02,285 - app.training.lambda_cloud_provisioner - INFO - Ensuring SSH key configuration...
2025-10-18 20:46:02,517 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:46:02,532 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:46:02,535 - app.training.lambda_cloud_provisioner - INFO - Checking available GPU instance types...
2025-10-18 20:46:03,143 - app.training.lambda_cloud_provisioner - INFO - Found 8 available GPU instance types
2025-10-18 20:46:03,148 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_gh200: 1x GH200 (96 GB) ($1.49/hr)
2025-10-18 20:46:03,152 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_b200_sxm6: 8x B200 (180 GB SXM6) ($39.92/hr)
2025-10-18 20:46:03,153 - app.training.lambda_cloud_provisioner - INFO -   - gpu_2x_h100_sxm5: 2x H100 (80 GB SXM5) ($6.38/hr)
2025-10-18 20:46:03,155 - app.training.lambda_cloud_provisioner - INFO - Selected instance type: gpu_1x_gh200 (GH200 (96 GB)) at $1.49/hr
2025-10-18 20:46:03,166 - app.training.lambda_cloud_provisioner - INFO - Saved Lambda Cloud configuration
2025-10-18 20:46:03,167 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud infrastructure initialized successfully
2025-10-18 20:46:03,167 - app.main - INFO - Lambda Cloud GPU training initialized successfully
2025-10-18 20:46:03,168 - app.main - INFO - Cloud GPU training system ready
2025-10-18 20:46:03,558 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud training infrastructure is ready
2025-10-18 20:46:16,264 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613 added to queue with priority 0
2025-10-18 20:46:16,889 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:46:26,200 - app.training.gpu_queue_manager - INFO - Existing instances: dict_items([('13873712efae4a898ebbf5094c7b77a0', {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': None, 'provider': 'lambda', 'status': 'idle', 'last_used': datetime.datetime(2025, 10, 18, 20, 46, 2, 260078), 'instance': {'id': '13873712efae4a898ebbf5094c7b77a0', 'name': 'lambda-gpu-20251018201800', 'ip': '192.222.57.28', 'private_ip': '172.26.132.108', 'status': 'active', 'ssh_key_names': ['understudy-key-v2'], 'file_system_names': [], 'region': {'name': 'us-east-3', 'description': 'Washington DC, USA'}, 'instance_type': {'name': 'gpu_1x_gh200', 'description': '1x GH200 (96 GB)', 'gpu_description': 'GH200 (96 GB)', 'price_cents_per_hour': 149, 'specs': {'vcpus': 64, 'memory_gib': 432, 'storage_gib': 4096, 'gpus': 1}}, 'hostname': '192-222-57-28', 'jupyter_token': '55ac7aa49a0c4d6ba29bf55214ba2a1c', 'jupyter_url': 'https://ad2f3f68cd1e4ba788d0490a345846b0-0.lambdaspaces.com/?token=55ac7aa49a0c4d6ba29bf55214ba2a1c', 'is_reserved': False, 'actions': {'migrate': {'available': True}, 'rebuild': {'available': True}, 'restart': {'available': True}, 'cold_reboot': {'available': True}, 'terminate': {'available': True}}, 'firewall_rulesets': []}})])
2025-10-18 20:46:26,213 - app.training.gpu_queue_manager - INFO - Reusing Lambda instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:46:26,258 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613 on lambda lambda-gpu-20251018201800
2025-10-18 20:46:26,263 - app.training.lambda_cloud_trainer - INFO - Starting training execution on instance 13873712efae4a898ebbf5094c7b77a0
2025-10-18 20:46:43,675 - app.training.lambda_cloud_trainer - INFO - SCRIPT:
2025-10-18 20:46:43,694 - app.training.lambda_cloud_trainer - INFO - #!/usr/bin/env python3
# Training script for job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613
# Endpoint: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4
# Generated at: 2025-10-18T20:46:43.673446

import json
import torch
import os
from datetime import datetime

from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM, 
    TrainingArguments, 
    Trainer,
    DataCollatorForLanguageModeling,
    BitsAndBytesConfig
)
from peft import LoraConfig, get_peft_model, TaskType
from datasets import Dataset
import codecarbon
import accelerate

print("=" * 50)
print(f"Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613")
print("Model: meta-llama/Llama-3.2-1B")
print(f"Device: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}")
print("=" * 50)

try:
    with open("training_data.json", "r") as f:
        raw_training_data = json.load(f)
except Exception as e:
    raise ValueError(f"Failed to load training data: {e}")

if isinstance(raw_training_data, str):
    pairs = raw_training_data.strip().split("\n\n")
    training_data = []
    for pair in pairs:
        if pair.strip():
            training_data.append({"text": pair.strip()})
else:
    training_data = raw_training_data

print(f"Loaded {len(training_data)} training examples")

if len(training_data) == 0:
    raise ValueError("No training data found")
if len(training_data) < 5:
    raise ValueError(f"Insufficient training data: {len(training_data)} examples (minimum 5 required)")

tracker = codecarbon.EmissionsTracker(
    project_name="understudy-b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4",
    measure_power_secs=15
)

tracker.start()

try:
    hf_token = "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"
    if not hf_token or hf_token == "None":
        raise ValueError("HuggingFace token is required but not provided")
    
    model_name = "meta-llama/Llama-3.2-1B"
    
    print("Loading tokenizer...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)
    except Exception as e:
        raise ValueError(f"Failed to load tokenizer: {e}")
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "right"
    
    print("Loading base model...")
    try:
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True,
            token=hf_token
        )
    except Exception as e:
        raise ValueError(f"Failed to load model: {e}")

    print(f"Model loaded: {model}")
    
    print("Configuring LoRA...")
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        lora_dropout=0.1,
        bias="none",
        task_type=TaskType.CAUSAL_LM
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    model.train()
    model.gradient_checkpointing_enable()
    
    lora_param_count = 0
    for name, param in model.named_parameters():
        if "lora" in name.lower():
            param.requires_grad_(True)
            lora_param_count += param.numel()
            print(f"LoRA parameter: {name}, requires_grad: {param.requires_grad}")
    
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total trainable parameters: {trainable_params}")
    print(f"LoRA parameters: {lora_param_count}")
    
    if trainable_params == 0:
        raise ValueError("No trainable parameters found!")
    
    print("Preparing dataset...")
    def tokenize_function(examples):
        return tokenizer(
            examples["text"],
            truncation=True,
            padding="max_length",
            max_length=512,
            return_tensors=None
        )
    
    dataset = Dataset.from_list(training_data)
    tokenized_dataset = dataset.map(
        tokenize_function,
        batched=True,
        remove_columns=dataset.column_names
    )
    
    split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)
    train_dataset = split_dataset["train"]
    eval_dataset = split_dataset["test"]
    
    print(f"Train samples: {len(train_dataset)}, Eval samples: {len(eval_dataset)}")
    
    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
    
    training_args = TrainingArguments(
        output_dir="./results",
        num_train_epochs=1,
        per_device_train_batch_size=2,
        per_device_eval_batch_size=4,
        gradient_accumulation_steps=4,
        warmup_ratio=0.1,
        learning_rate=0.0002,
        fp16=True,
        logging_steps=10,
        eval_strategy="steps",
        eval_steps=50,
        save_strategy="steps",
        save_steps=100,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        report_to="none",
        optim="paged_adamw_8bit",
        lr_scheduler_type="cosine",
        gradient_checkpointing=True,
        max_grad_norm=0.3,
        group_by_length=True,
        ddp_find_unused_parameters=False
    )
    
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        data_collator=data_collator,
        tokenizer=tokenizer
    )
    
    print("Starting training...")
    print("-" * 50)
    try:
        train_result = trainer.train()
    except RuntimeError as e:
        if "does not require grad" in str(e):
            raise ValueError(f"Gradient computation error: {e}")
        raise ValueError(f"Training failed: {e}")
    except Exception as e:
        raise ValueError(f"Training failed: {e}")
    
    print("-" * 50)
    print("Training completed!")
    print(f"Final training loss: {train_result.training_loss:.4f}")
    
    print("Saving model...")
    os.makedirs("./final_model", exist_ok=True)
    trainer.save_model("./final_model")
    tokenizer.save_pretrained("./final_model")
    
    metrics = {
        "train_loss": train_result.training_loss,
        "train_runtime": train_result.metrics["train_runtime"],
        "train_samples_per_second": train_result.metrics["train_samples_per_second"],
        "epoch": train_result.metrics["epoch"]
    }
    
    with open("./final_model/training_metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)
    
    print("Model saved successfully!")
    
finally:
    emissions = tracker.stop()
    print(f"Carbon emissions: {emissions:.6f} kg CO2")
    
    os.makedirs("./final_model", exist_ok=True)
    with open("./final_model/carbon_emissions.json", "w") as f:
        json.dump({"emissions_kg": emissions, "timestamp": datetime.utcnow().isoformat()}, f)

print("=" * 50)
print("Training job completed successfully!")

2025-10-18 20:46:43,705 - app.training.lambda_cloud_trainer - INFO - Attempting SSH connection to 192.222.57.28 with username 'ubuntu' (attempt 1/10)
2025-10-18 20:46:43,710 - app.training.lambda_cloud_trainer - INFO - Using SSH key: /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:46:43,713 - app.training.lambda_cloud_trainer - INFO - SSH key permissions: 600
2025-10-18 20:46:43,770 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-18 20:46:43,914 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-18 20:46:43,915 - app.training.lambda_cloud_trainer - INFO - SSH connection established to 192.222.57.28 with username 'ubuntu'
2025-10-18 20:47:15,154 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-18 20:47:27,965 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-18 20:47:28,929 - app.training.lambda_cloud_trainer - INFO - Installing Lambda Cloud compatible dependencies...
2025-10-18 20:48:17,545 - app.training.lambda_cloud_trainer - INFO - Starting training...
2025-10-18 20:48:30,720 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon WARNING @ 20:48:22] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-18 20:48:30,726 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] [setup] RAM Tracking...
2025-10-18 20:48:30,727 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] [setup] CPU Tracking...
2025-10-18 20:48:30,728 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon WARNING @ 20:48:22] We saw that you have a Neoverse-V2 but we don't know it. Please contact us.
2025-10-18 20:48:30,730 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon WARNING @ 20:48:22] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-18 20:48:30,731 - app.training.lambda_cloud_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-18 20:48:30,732 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:30,733 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] CPU Model on constant consumption mode: Neoverse-V2
2025-10-18 20:48:30,733 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon WARNING @ 20:48:22] No CPU tracking mode found. Falling back on CPU constant mode.
2025-10-18 20:48:30,734 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] [setup] GPU Tracking...
2025-10-18 20:48:30,735 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] Tracking Nvidia GPU via pynvml
2025-10-18 20:48:30,736 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] The below tracking methods have been set up:
2025-10-18 20:48:30,737 - app.training.lambda_cloud_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-18 20:48:30,738 - app.training.lambda_cloud_trainer - INFO - Training output: CPU Tracking Method: global constant
2025-10-18 20:48:30,739 - app.training.lambda_cloud_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-18 20:48:30,740 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:30,741 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22] >>> Tracker's metadata:
2025-10-18 20:48:30,742 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   Platform system: Linux-6.8.0-1013-nvidia-64k-aarch64-with-glibc2.35
2025-10-18 20:48:30,746 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   Python version: 3.10.12
2025-10-18 20:48:30,748 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   CodeCarbon version: 3.0.7
2025-10-18 20:48:30,750 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   Available RAM : 525.679 GB
2025-10-18 20:48:30,751 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   CPU count: 64 thread(s) in 1 physical CPU(s)
2025-10-18 20:48:30,752 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   CPU model: Neoverse-V2
2025-10-18 20:48:30,753 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   GPU count: 1
2025-10-18 20:48:30,754 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:22]   GPU model: 1 x NVIDIA GH200 480GB
2025-10-18 20:48:30,755 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:25] Emissions data (if any) will be saved to file /home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/emissions.csv
2025-10-18 20:48:30,757 - app.training.lambda_cloud_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-18 20:48:30,758 - app.training.lambda_cloud_trainer - INFO - Training output: ==================================================
2025-10-18 20:48:30,759 - app.training.lambda_cloud_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613
2025-10-18 20:48:30,760 - app.training.lambda_cloud_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-18 20:48:30,760 - app.training.lambda_cloud_trainer - INFO - Training output: Device: CPU
2025-10-18 20:48:30,761 - app.training.lambda_cloud_trainer - INFO - Training output: ==================================================
2025-10-18 20:48:30,762 - app.training.lambda_cloud_trainer - INFO - Training output: Loaded 21 training examples
2025-10-18 20:48:30,763 - app.training.lambda_cloud_trainer - INFO - Training output: Loading tokenizer...
2025-10-18 20:48:30,766 - app.training.lambda_cloud_trainer - INFO - Training output: Loading base model...
2025-10-18 20:48:30,768 - app.training.lambda_cloud_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-18 20:48:30,769 - app.training.lambda_cloud_trainer - INFO - Training output: (model): LlamaModel(
2025-10-18 20:48:30,770 - app.training.lambda_cloud_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-18 20:48:30,772 - app.training.lambda_cloud_trainer - INFO - Training output: (layers): ModuleList(
2025-10-18 20:48:30,773 - app.training.lambda_cloud_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-18 20:48:30,774 - app.training.lambda_cloud_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-18 20:48:30,775 - app.training.lambda_cloud_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-18 20:48:30,775 - app.training.lambda_cloud_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-18 20:48:30,776 - app.training.lambda_cloud_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-18 20:48:30,777 - app.training.lambda_cloud_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-18 20:48:30,777 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,778 - app.training.lambda_cloud_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-18 20:48:30,779 - app.training.lambda_cloud_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-18 20:48:30,780 - app.training.lambda_cloud_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-18 20:48:30,781 - app.training.lambda_cloud_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-18 20:48:30,782 - app.training.lambda_cloud_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-18 20:48:30,782 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,783 - app.training.lambda_cloud_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-18 20:48:30,784 - app.training.lambda_cloud_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-18 20:48:30,784 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,785 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,786 - app.training.lambda_cloud_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-18 20:48:30,786 - app.training.lambda_cloud_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-18 20:48:30,787 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,788 - app.training.lambda_cloud_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-18 20:48:30,790 - app.training.lambda_cloud_trainer - INFO - Training output: )
2025-10-18 20:48:30,790 - app.training.lambda_cloud_trainer - INFO - Training output: Configuring LoRA...
2025-10-18 20:48:30,791 - app.training.lambda_cloud_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-18 20:48:30,792 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,793 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,794 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,795 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,799 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,800 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,801 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,802 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,803 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,803 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,804 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,805 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,805 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,806 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,807 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,808 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,809 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,809 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,810 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,811 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,812 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,813 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,814 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,815 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,815 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,816 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,817 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,817 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,818 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,819 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,820 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,820 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,821 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,822 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,823 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,824 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,824 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,825 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,826 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,827 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,828 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,829 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,830 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,831 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,831 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,832 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,833 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,834 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,835 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,837 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,838 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,838 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,839 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,840 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,841 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,842 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,843 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,844 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,844 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,845 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,846 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,847 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,848 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,849 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,850 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,851 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,851 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,852 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,853 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,854 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,855 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,856 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,857 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,857 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,858 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,859 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,859 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,860 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,861 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,861 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,862 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,863 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,864 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,866 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,867 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,869 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,870 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,871 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,872 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,873 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,874 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,875 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,876 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,877 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,878 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,879 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,880 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,881 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,882 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,883 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,884 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,884 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,885 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,886 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,887 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,888 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,889 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,890 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,891 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,891 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,892 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,893 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,894 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,895 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,896 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,896 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,898 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,898 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,899 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,900 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,901 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,901 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,902 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,903 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,904 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,905 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,905 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,906 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,907 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,907 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,908 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,909 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,910 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,911 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,911 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,912 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,913 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,914 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,915 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,915 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,916 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,917 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,917 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,918 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,919 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,919 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,920 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,921 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,922 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,924 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,925 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,925 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,926 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,928 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,929 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,930 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,932 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,934 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,936 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,937 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,937 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,939 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,941 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,942 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,942 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,943 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,944 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,944 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,946 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,947 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,948 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,949 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,950 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,951 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,954 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,956 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,957 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,958 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,962 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,964 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,965 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,966 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,966 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,967 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,968 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,969 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,970 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,971 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,972 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,973 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,974 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,975 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,975 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,976 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,977 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,977 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,978 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,978 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,979 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,980 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,981 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,982 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,982 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,983 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,984 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,985 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,986 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,986 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,987 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,988 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,989 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,990 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,990 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,991 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,992 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,993 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,994 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,994 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,995 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,996 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,997 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,997 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:30,998 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-18 20:48:30,999 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-18 20:48:31,000 - app.training.lambda_cloud_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-18 20:48:31,001 - app.training.lambda_cloud_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-18 20:48:31,001 - app.training.lambda_cloud_trainer - INFO - Training output: Preparing dataset...
2025-10-18 20:48:31,002 - app.training.lambda_cloud_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 2387.52 examples/s]
2025-10-18 20:48:31,003 - app.training.lambda_cloud_trainer - INFO - Training output: /home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-18 20:48:31,004 - app.training.lambda_cloud_trainer - INFO - Training output: trainer = Trainer(
2025-10-18 20:48:31,004 - app.training.lambda_cloud_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-18 20:48:31,005 - app.training.lambda_cloud_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-18 20:48:31,007 - app.training.lambda_cloud_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-18 20:48:31,008 - app.training.lambda_cloud_trainer - INFO - Training output: Starting training...
2025-10-18 20:48:31,009 - app.training.lambda_cloud_trainer - INFO - Training output: --------------------------------------------------
2025-10-18 20:48:31,010 - app.training.lambda_cloud_trainer - INFO - Training output: 0%|          | 0/3 [00:00<?, ?it/s]/home/ubuntu/training_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
2025-10-18 20:48:31,010 - app.training.lambda_cloud_trainer - INFO - Training output: warnings.warn(warn_msg)
2025-10-18 20:48:31,011 - app.training.lambda_cloud_trainer - INFO - Training output: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-18 20:48:31,012 - app.training.lambda_cloud_trainer - INFO - Training output: /home/ubuntu/training_env/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
2025-10-18 20:48:31,013 - app.training.lambda_cloud_trainer - INFO - Training output: warnings.warn(
2025-10-18 20:48:36,664 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:36] Energy consumed for RAM : 0.000038 kWh. RAM Power : 12.600000000000001 W
2025-10-18 20:48:37,300 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:36] Delta energy consumed for CPU with constant : 0.000128 kWh, power : 42.5 W
2025-10-18 20:48:37,305 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:36] Energy consumed for All CPU : 0.000128 kWh
2025-10-18 20:48:37,312 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:36] Energy consumed for all GPUs : 0.000783 kWh. Total GPU Power : 260.958339273278 W
2025-10-18 20:48:37,316 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon INFO @ 20:48:36] 0.000948 kWh of electricity used since the beginning.
2025-10-18 20:48:37,318 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon ERROR @ 20:48:36] Region:  not found for Country with ISO CODE : USA
2025-10-18 20:48:37,319 - app.training.lambda_cloud_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-18 20:48:37,322 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/train.py", line 184, in <module>
2025-10-18 20:48:37,324 - app.training.lambda_cloud_trainer - INFO - Training output: train_result = trainer.train()
2025-10-18 20:48:37,325 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
2025-10-18 20:48:37,326 - app.training.lambda_cloud_trainer - INFO - Training output: return inner_training_loop(
2025-10-18 20:48:37,327 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
2025-10-18 20:48:37,328 - app.training.lambda_cloud_trainer - INFO - Training output: tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
2025-10-18 20:48:37,329 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 4071, in training_step
2025-10-18 20:48:37,330 - app.training.lambda_cloud_trainer - INFO - Training output: self.accelerator.backward(loss, **kwargs)
2025-10-18 20:48:37,331 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/accelerate/accelerator.py", line 2734, in backward
2025-10-18 20:48:37,333 - app.training.lambda_cloud_trainer - INFO - Training output: loss.backward(**kwargs)
2025-10-18 20:48:37,334 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/_tensor.py", line 625, in backward
2025-10-18 20:48:37,335 - app.training.lambda_cloud_trainer - INFO - Training output: torch.autograd.backward(
2025-10-18 20:48:37,336 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354, in backward
2025-10-18 20:48:37,337 - app.training.lambda_cloud_trainer - INFO - Training output: _engine_run_backward(
2025-10-18 20:48:37,338 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
2025-10-18 20:48:37,339 - app.training.lambda_cloud_trainer - INFO - Training output: return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-10-18 20:48:37,339 - app.training.lambda_cloud_trainer - INFO - Training output: RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-18 20:48:37,343 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,344 - app.training.lambda_cloud_trainer - INFO - Training output: During handling of the above exception, another exception occurred:
2025-10-18 20:48:37,346 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,347 - app.training.lambda_cloud_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-18 20:48:37,347 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/train.py", line 187, in <module>
2025-10-18 20:48:37,348 - app.training.lambda_cloud_trainer - INFO - Training output: raise ValueError(f"Gradient computation error: {e}")
2025-10-18 20:48:37,349 - app.training.lambda_cloud_trainer - INFO - Training output: ValueError: Gradient computation error: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-18 20:48:37,352 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,353 - app.training.lambda_cloud_trainer - INFO - Training output: During handling of the above exception, another exception occurred:
2025-10-18 20:48:37,354 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,356 - app.training.lambda_cloud_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-18 20:48:37,356 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-18 20:48:37,357 - app.training.lambda_cloud_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-18 20:48:37,358 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-18 20:48:37,359 - app.training.lambda_cloud_trainer - INFO - Training output: raise ValueError(
2025-10-18 20:48:37,359 - app.training.lambda_cloud_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-18 20:48:37,360 - app.training.lambda_cloud_trainer - INFO - Training output: [codecarbon WARNING @ 20:48:36] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-18 20:48:37,362 - app.training.lambda_cloud_trainer - INFO - Training output: Carbon emissions: 0.000350 kg CO2
2025-10-18 20:48:37,363 - app.training.lambda_cloud_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-18 20:48:37,363 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/train.py", line 184, in <module>
2025-10-18 20:48:37,365 - app.training.lambda_cloud_trainer - INFO - Training output: train_result = trainer.train()
2025-10-18 20:48:37,366 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
2025-10-18 20:48:37,367 - app.training.lambda_cloud_trainer - INFO - Training output: return inner_training_loop(
2025-10-18 20:48:37,367 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
2025-10-18 20:48:37,368 - app.training.lambda_cloud_trainer - INFO - Training output: tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
2025-10-18 20:48:37,369 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/transformers/trainer.py", line 4071, in training_step
2025-10-18 20:48:37,370 - app.training.lambda_cloud_trainer - INFO - Training output: self.accelerator.backward(loss, **kwargs)
2025-10-18 20:48:37,371 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/accelerate/accelerator.py", line 2734, in backward
2025-10-18 20:48:37,372 - app.training.lambda_cloud_trainer - INFO - Training output: loss.backward(**kwargs)
2025-10-18 20:48:37,373 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/_tensor.py", line 625, in backward
2025-10-18 20:48:37,373 - app.training.lambda_cloud_trainer - INFO - Training output: torch.autograd.backward(
2025-10-18 20:48:37,374 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354, in backward
2025-10-18 20:48:37,375 - app.training.lambda_cloud_trainer - INFO - Training output: _engine_run_backward(
2025-10-18 20:48:37,376 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
2025-10-18 20:48:37,377 - app.training.lambda_cloud_trainer - INFO - Training output: return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-10-18 20:48:37,378 - app.training.lambda_cloud_trainer - INFO - Training output: RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-18 20:48:37,379 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,380 - app.training.lambda_cloud_trainer - INFO - Training output: During handling of the above exception, another exception occurred:
2025-10-18 20:48:37,381 - app.training.lambda_cloud_trainer - INFO - Training output: 
2025-10-18 20:48:37,382 - app.training.lambda_cloud_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-18 20:48:37,384 - app.training.lambda_cloud_trainer - INFO - Training output: File "/home/ubuntu/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613/train.py", line 187, in <module>
2025-10-18 20:48:37,386 - app.training.lambda_cloud_trainer - INFO - Training output: raise ValueError(f"Gradient computation error: {e}")
2025-10-18 20:48:37,387 - app.training.lambda_cloud_trainer - INFO - Training output: ValueError: Gradient computation error: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-18 20:48:37,388 - app.training.lambda_cloud_trainer - INFO - Training output: 0%|          | 0/3 [00:06<?, ?it/s]
2025-10-18 20:48:37,391 - app.training.lambda_cloud_trainer - INFO - Downloading trained model...
2025-10-18 20:48:37,460 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-18 20:48:37,501 - app.training.lambda_cloud_trainer - INFO - Downloading carbon_emissions.json...
2025-10-18 20:48:37,661 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-18 20:48:37,665 - app.training.lambda_cloud_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613
2025-10-18 20:48:37,668 - app.training.lambda_cloud_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613
2025-10-18 20:48:37,679 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251018_204613
2025-10-18 20:53:48,024 - app.main - INFO - Shutting down Understudy API...
2025-10-18 20:54:01,590 - app.main - INFO - Starting Understudy API...
2025-10-18 20:54:01,625 - app.main - INFO - Database initialized
2025-10-18 20:54:01,685 - app.main - INFO - Initializing GPU training queue...
2025-10-18 20:54:01,686 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-18 20:54:01,697 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-18 20:54:01,699 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-18 20:54:01,699 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-18 20:54:01,700 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-18 20:54:01,701 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-18 20:54:01,805 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-18 20:54:01,808 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-18 20:54:02,054 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:54:02,057 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:54:02,802 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 20:54:02,810 - app.training.gpu_queue_manager - INFO - Checking 1 existing Lambda instances for reuse eligibility
2025-10-18 20:54:02,814 - app.training.gpu_queue_manager - INFO - Instance: name='lambda-gpu-20251018201800', status='active', id='13873712efae4a898ebbf5094c7b77a0'
2025-10-18 20:54:02,817 - app.training.gpu_queue_manager - INFO - Instance SSH keys: ['understudy-key-v2']
2025-10-18 20:54:02,819 - app.training.gpu_queue_manager - INFO - Found existing Lambda instance: lambda-gpu-20251018201800 (13873712efae4a898ebbf5094c7b77a0)
2025-10-18 20:54:02,821 - app.training.gpu_queue_manager - INFO - Discovered 1 existing Lambda instances available for reuse
2025-10-18 20:54:02,823 - app.main - INFO - Initializing Lambda Cloud GPU training...
2025-10-18 20:54:02,839 - app.training.lambda_cloud_provisioner - INFO - Initializing Lambda Cloud infrastructure...
2025-10-18 20:54:02,849 - app.training.lambda_cloud_provisioner - INFO - Loaded Lambda Cloud configuration from file
2025-10-18 20:54:02,851 - app.training.lambda_cloud_provisioner - INFO - Ensuring SSH key configuration...
2025-10-18 20:54:03,321 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 20:54:03,324 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 20:54:03,327 - app.training.lambda_cloud_provisioner - INFO - Checking available GPU instance types...
2025-10-18 20:54:03,963 - app.training.lambda_cloud_provisioner - INFO - Found 8 available GPU instance types
2025-10-18 20:54:03,966 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_gh200: 1x GH200 (96 GB) ($1.49/hr)
2025-10-18 20:54:03,969 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_b200_sxm6: 8x B200 (180 GB SXM6) ($39.92/hr)
2025-10-18 20:54:03,973 - app.training.lambda_cloud_provisioner - INFO -   - gpu_2x_h100_sxm5: 2x H100 (80 GB SXM5) ($6.38/hr)
2025-10-18 20:54:03,979 - app.training.lambda_cloud_provisioner - INFO - Selected instance type: gpu_1x_gh200 (GH200 (96 GB)) at $1.49/hr
2025-10-18 20:54:03,991 - app.training.lambda_cloud_provisioner - INFO - Saved Lambda Cloud configuration
2025-10-18 20:54:03,992 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud infrastructure initialized successfully
2025-10-18 20:54:03,993 - app.main - INFO - Lambda Cloud GPU training initialized successfully
2025-10-18 20:54:03,994 - app.main - INFO - Cloud GPU training system ready
2025-10-18 21:13:03,422 - app.main - INFO - Shutting down Understudy API...
2025-10-18 21:13:15,595 - app.main - INFO - Starting Understudy API...
2025-10-18 21:13:15,622 - app.main - INFO - Database initialized
2025-10-18 21:13:15,674 - app.main - INFO - Initializing GPU training queue...
2025-10-18 21:13:15,675 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-18 21:13:15,684 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-18 21:13:15,686 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-18 21:13:15,687 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-18 21:13:15,688 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-18 21:13:15,689 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-18 21:13:15,770 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-18 21:13:15,772 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-18 21:13:16,291 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 21:13:16,309 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 21:13:17,054 - app.training.lambda_cloud_trainer - INFO - Found 1 existing Lambda Cloud instances
2025-10-18 21:13:17,068 - app.training.gpu_queue_manager - INFO - Checking 1 existing Lambda instances for reuse eligibility
2025-10-18 21:13:17,072 - app.training.gpu_queue_manager - INFO - Instance: name='lambda-gpu-20251018201800', status='active', id='13873712efae4a898ebbf5094c7b77a0'
2025-10-18 21:13:17,073 - app.training.gpu_queue_manager - INFO - Instance SSH keys: ['understudy-key-v2']
2025-10-18 21:13:17,075 - app.training.gpu_queue_manager - INFO - Found existing Lambda instance: lambda-gpu-20251018201800 (13873712efae4a898ebbf5094c7b77a0)
2025-10-18 21:13:17,076 - app.training.gpu_queue_manager - INFO - Discovered 1 existing Lambda instances available for reuse
2025-10-18 21:13:17,078 - app.main - INFO - Initializing Lambda Cloud GPU training...
2025-10-18 21:13:17,086 - app.training.lambda_cloud_provisioner - INFO - Initializing Lambda Cloud infrastructure...
2025-10-18 21:13:17,093 - app.training.lambda_cloud_provisioner - INFO - Loaded Lambda Cloud configuration from file
2025-10-18 21:13:17,095 - app.training.lambda_cloud_provisioner - INFO - Ensuring SSH key configuration...
2025-10-18 21:13:17,290 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-18 21:13:17,293 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-18 21:13:17,296 - app.training.lambda_cloud_provisioner - INFO - Checking available GPU instance types...
2025-10-18 21:13:17,758 - app.training.lambda_cloud_provisioner - INFO - Found 8 available GPU instance types
2025-10-18 21:13:17,762 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_gh200: 1x GH200 (96 GB) ($1.49/hr)
2025-10-18 21:13:17,766 - app.training.lambda_cloud_provisioner - INFO -   - gpu_8x_b200_sxm6: 8x B200 (180 GB SXM6) ($39.92/hr)
2025-10-18 21:13:17,792 - app.training.lambda_cloud_provisioner - INFO -   - gpu_1x_h100_sxm5: 1x H100 (80 GB SXM5) ($3.29/hr)
2025-10-18 21:13:17,814 - app.training.lambda_cloud_provisioner - INFO - Selected instance type: gpu_1x_gh200 (GH200 (96 GB)) at $1.49/hr
2025-10-18 21:13:17,979 - app.training.lambda_cloud_provisioner - INFO - Saved Lambda Cloud configuration
2025-10-18 21:13:17,980 - app.training.lambda_cloud_provisioner - INFO - Lambda Cloud infrastructure initialized successfully
2025-10-18 21:13:17,981 - app.main - INFO - Lambda Cloud GPU training initialized successfully
2025-10-18 21:13:17,982 - app.main - INFO - Cloud GPU training system ready
2025-10-18 22:01:28,795 - app.main - INFO - Shutting down Understudy API...
2025-10-19 13:13:01,516 - app.main - INFO - Starting Understudy API...
2025-10-19 13:13:01,554 - app.main - INFO - Database initialized
2025-10-19 13:13:01,627 - app.main - INFO - Initializing GPU training queue...
2025-10-19 13:13:01,628 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 13:13:01,637 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 13:13:01,638 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 13:13:01,639 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 13:13:01,640 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 13:13:01,640 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 13:13:01,730 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 13:13:01,733 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 13:13:02,187 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 13:13:02,188 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 13:13:02,931 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 13:13:02,935 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 13:13:02,936 - app.main - INFO - Cloud GPU training system ready
2025-10-19 13:32:57,119 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_133257 added to queue with priority 0
2025-10-19 13:33:05,924 - app.training.runpod_trainer - INFO - Launching RunPod instance: runpod-gpu-20251019133305
2025-10-19 13:34:30,025 - app.training.runpod_trainer - INFO - Pod cy1rhw9qo8e9mp launched successfully at 149.36.0.150:25221
2025-10-19 13:34:30,033 - app.training.gpu_queue_manager - INFO - Created new RunPod pod runpod-gpu-20251019133305
2025-10-19 13:34:30,044 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_133257 on runpod runpod-gpu-20251019133305
2025-10-19 13:34:30,046 - app.training.runpod_trainer - INFO - Starting training execution on pod cy1rhw9qo8e9mp
2025-10-19 13:34:30,049 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 13:34:30,052 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 1/10)
2025-10-19 13:34:30,269 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 13:34:30,733 - paramiko.transport - INFO - Authentication (password) failed.
2025-10-19 13:34:30,736 - app.training.runpod_trainer - WARNING - SSH connection failed: Authentication failed.
2025-10-19 13:34:30,740 - app.training.runpod_trainer - INFO - Retrying in 10s...
2025-10-19 13:34:40,755 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 2/10)
2025-10-19 13:34:40,996 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 13:34:41,459 - paramiko.transport - INFO - Authentication (password) failed.
2025-10-19 13:34:41,467 - app.training.runpod_trainer - WARNING - SSH connection failed: Authentication failed.
2025-10-19 13:34:41,476 - app.training.runpod_trainer - INFO - Retrying in 20s...
2025-10-19 13:35:01,491 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 3/10)
2025-10-19 13:35:01,741 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 13:35:02,174 - paramiko.transport - INFO - Authentication (password) failed.
2025-10-19 13:35:02,178 - app.training.runpod_trainer - WARNING - SSH connection failed: Authentication failed.
2025-10-19 13:35:02,181 - app.training.runpod_trainer - INFO - Retrying in 30s...
2025-10-19 13:35:32,187 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 4/10)
2025-10-19 13:35:32,434 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 13:35:32,898 - paramiko.transport - INFO - Authentication (password) failed.
2025-10-19 13:35:32,904 - app.training.runpod_trainer - WARNING - SSH connection failed: Authentication failed.
2025-10-19 13:35:32,906 - app.training.runpod_trainer - INFO - Retrying in 40s...
2025-10-19 13:36:12,908 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 5/10)
2025-10-19 13:36:13,052 - app.training.runpod_trainer - WARNING - SSH connection failed: [Errno None] Unable to connect to port 25221 on 149.36.0.150
2025-10-19 13:36:13,061 - app.training.runpod_trainer - INFO - Retrying in 50s...
2025-10-19 13:37:03,073 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 6/10)
2025-10-19 13:37:03,202 - app.training.runpod_trainer - WARNING - SSH connection failed: [Errno None] Unable to connect to port 25221 on 149.36.0.150
2025-10-19 13:37:03,207 - app.training.runpod_trainer - INFO - Retrying in 60s...
2025-10-19 13:38:03,218 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 7/10)
2025-10-19 13:38:03,428 - app.training.runpod_trainer - WARNING - SSH connection failed: [Errno None] Unable to connect to port 25221 on 149.36.0.150
2025-10-19 13:38:03,434 - app.training.runpod_trainer - INFO - Retrying in 70s...
2025-10-19 13:39:13,449 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 8/10)
2025-10-19 13:39:13,584 - app.training.runpod_trainer - WARNING - SSH connection failed: [Errno None] Unable to connect to port 25221 on 149.36.0.150
2025-10-19 13:39:13,592 - app.training.runpod_trainer - INFO - Retrying in 80s...
2025-10-19 13:40:33,603 - app.training.runpod_trainer - INFO - Attempting SSH connection to 149.36.0.150:25221 (attempt 9/10)
2025-10-19 13:40:33,751 - app.training.runpod_trainer - WARNING - SSH connection failed: [Errno None] Unable to connect to port 25221 on 149.36.0.150
2025-10-19 13:40:33,757 - app.training.runpod_trainer - INFO - Retrying in 90s...
2025-10-19 13:40:36,439 - app.main - INFO - Shutting down Understudy API...
2025-10-19 13:40:50,199 - app.main - INFO - Starting Understudy API...
2025-10-19 13:40:50,237 - app.main - INFO - Database initialized
2025-10-19 13:40:50,307 - app.main - INFO - Initializing GPU training queue...
2025-10-19 13:40:50,308 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 13:40:50,316 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 13:40:50,317 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 13:40:50,318 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 13:40:50,318 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 13:40:50,319 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 13:40:50,421 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 13:40:50,424 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 13:40:50,800 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 13:40:50,810 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 13:40:51,807 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 13:40:51,816 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 13:40:51,829 - app.main - INFO - Cloud GPU training system ready
2025-10-19 13:41:13,476 - app.main - INFO - Shutting down Understudy API...
2025-10-19 14:08:11,264 - app.main - INFO - Starting Understudy API...
2025-10-19 14:08:11,285 - app.main - INFO - Database initialized
2025-10-19 14:08:11,336 - app.main - INFO - Initializing GPU training queue...
2025-10-19 14:08:11,337 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 14:08:11,345 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 14:08:11,346 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 14:08:11,347 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 14:08:11,347 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 14:08:11,348 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 14:08:11,426 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 14:08:11,430 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 14:08:11,692 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 14:08:11,693 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 14:08:12,493 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 14:08:12,500 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 14:08:12,504 - app.main - INFO - Cloud GPU training system ready
2025-10-19 14:08:15,876 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815 added to queue with priority 0
2025-10-19 14:08:21,473 - app.training.runpod_trainer - INFO - Launching RunPod instance: runpod-gpu-20251019140821
2025-10-19 14:09:18,132 - app.training.runpod_trainer - INFO - Pod 0dvhvi1fp92dhs launched successfully at 213.173.110.71:19277
2025-10-19 14:09:18,151 - app.training.gpu_queue_manager - INFO - Created new RunPod pod runpod-gpu-20251019140821
2025-10-19 14:09:18,171 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815 on runpod runpod-gpu-20251019140821
2025-10-19 14:09:18,187 - app.training.runpod_trainer - INFO - Starting training execution on pod 0dvhvi1fp92dhs
2025-10-19 14:09:18,199 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 14:09:32,133 - app.training.runpod_trainer - INFO - Attempting SSH connection to 213.173.110.71:19277 (attempt 1/10)
2025-10-19 14:09:51,400 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 14:10:04,973 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 14:10:05,513 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 14:10:09,488 - app.training.runpod_trainer - INFO - SSH connection established to 213.173.110.71:19277
2025-10-19 14:10:19,759 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 14:10:20,649 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 14:10:20,656 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 14:12:27,522 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 14:12:29,832 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /usr/local/lib/python3.10/dist-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
2025-10-19 14:12:29,840 - app.training.runpod_trainer - INFO - Training output: warn(
2025-10-19 14:12:30,435 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:12:30] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 14:12:30,443 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:30] [setup] RAM Tracking...
2025-10-19 14:12:30,444 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:30] [setup] CPU Tracking...
2025-10-19 14:12:31,518 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:12:31] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 14:12:31,522 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 14:12:31,526 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:12:31,534 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31] CPU Model on constant consumption mode: AMD Ryzen 9 7950X 16-Core Processor
2025-10-19 14:12:31,539 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:12:31] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 14:12:31,543 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31] [setup] GPU Tracking...
2025-10-19 14:12:31,545 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31] Tracking Nvidia GPU via pynvml
2025-10-19 14:12:31,547 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31] The below tracking methods have been set up:
2025-10-19 14:12:31,548 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 14:12:31,549 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 14:12:31,550 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 14:12:31,551 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:12:31,551 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31] >>> Tracker's metadata:
2025-10-19 14:12:31,553 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   Platform system: Linux-6.8.0-60-generic-x86_64-with-glibc2.35
2025-10-19 14:12:31,554 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   Python version: 3.10.12
2025-10-19 14:12:31,555 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   CodeCarbon version: 3.0.7
2025-10-19 14:12:31,556 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   Available RAM : 124.913 GB
2025-10-19 14:12:31,557 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   CPU count: 32 thread(s) in 1 physical CPU(s)
2025-10-19 14:12:31,558 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   CPU model: AMD Ryzen 9 7950X 16-Core Processor
2025-10-19 14:12:31,559 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   GPU count: 1
2025-10-19 14:12:31,560 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:31]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 14:12:34,758 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:34] Emissions data (if any) will be saved to file /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815/emissions.csv
2025-10-19 14:12:37,604 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 14:12:43,312 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:12:43,336 - app.training.runpod_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815
2025-10-19 14:12:43,339 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 14:12:43,342 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 14:12:43,344 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:12:43,346 - app.training.runpod_trainer - INFO - Training output: Loaded 21 training examples
2025-10-19 14:12:43,347 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 14:12:43,348 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 14:12:43,349 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 14:12:43,350 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 14:12:43,351 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 14:12:43,351 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 14:12:43,352 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 14:12:43,353 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 14:12:43,354 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:12:43,355 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:12:43,356 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:12:43,357 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:12:43,358 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,358 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 14:12:43,359 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:12:43,360 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:12:43,361 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 14:12:43,362 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 14:12:43,363 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,363 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:12:43,364 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:12:43,366 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,367 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,367 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:12:43,369 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 14:12:43,370 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,371 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 14:12:43,372 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:12:43,373 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 14:12:43,375 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 14:12:43,376 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,377 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,378 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,379 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,380 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,381 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,383 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,384 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,385 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,386 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,386 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,388 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,389 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,391 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,391 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,393 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,394 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,395 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,396 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,398 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,400 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,402 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,403 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,404 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,405 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,406 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,407 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,408 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,409 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,409 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,410 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,411 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,412 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,413 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,414 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,415 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,416 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,417 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,418 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,419 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,419 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,421 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,422 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,422 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,423 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,424 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,425 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,426 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,427 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,429 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,430 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,431 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,432 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,432 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,434 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,434 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,435 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,436 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,437 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,438 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,439 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,440 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,440 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,442 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,442 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,443 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,444 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,445 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,446 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,447 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,448 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,449 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,450 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,450 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,452 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,452 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,453 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,454 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,455 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,456 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,457 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,457 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,458 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,459 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,460 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,462 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,462 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,463 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,464 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,465 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,466 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,467 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,468 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,469 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,470 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,471 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,471 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,472 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,473 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,474 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,475 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,476 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,476 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,477 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,478 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,479 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,480 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,490 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,492 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,493 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,494 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,495 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,497 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,498 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,499 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,500 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,501 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,502 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,503 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,503 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,504 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,505 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,506 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,506 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,508 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,508 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,509 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,510 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,511 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,512 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,513 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,513 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,514 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,515 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,516 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,517 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,517 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,518 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,519 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,520 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,521 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,521 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,522 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,523 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,524 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,525 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,526 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,527 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,528 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,529 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,529 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,531 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,534 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,534 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,535 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,536 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,537 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,538 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,538 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,539 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,540 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,541 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,542 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,543 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,544 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,544 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,545 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,546 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,547 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,548 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,549 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,552 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,553 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,554 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,555 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,555 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,556 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,558 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,559 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,559 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,561 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,562 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,562 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,563 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,564 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,565 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,566 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,567 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,568 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,569 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,570 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,571 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,572 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,573 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,574 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,575 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,576 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,578 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,578 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,579 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,580 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,581 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,582 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,583 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,584 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,585 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,586 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,587 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,588 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,589 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,589 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,590 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,591 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,592 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,593 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,594 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,595 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,596 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,597 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,598 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,599 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,599 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,600 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:12:43,601 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:12:43,602 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 14:12:43,603 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 14:12:43,604 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 14:12:43,605 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 4220.23 examples/s]
2025-10-19 14:12:43,605 - app.training.runpod_trainer - INFO - Training output: /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 14:12:43,606 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 14:12:43,607 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 14:12:43,609 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 14:12:43,609 - app.training.runpod_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-19 14:12:43,610 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 14:12:43,611 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:12:43,612 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/3 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 14:12:44,946 - app.training.runpod_trainer - INFO - Training output: 33%|      | 1/3 [00:00<00:01,  1.44it/s] 67%|   | 2/3 [00:01<00:00,  1.91it/s]100%|| 3/3 [00:01<00:00,  3.01it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4f1dc-22728f7e7a9b3452094ac282;f1676938-4aef-47e0-81c3-89e15a3130e8)
2025-10-19 14:12:44,948 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:12:44,961 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:12:44,962 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:12:44,964 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:12:44,966 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:12:44,967 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:12:45,535 - app.training.runpod_trainer - INFO - Training output: 100%|| 3/3 [00:01<00:00,  3.01it/s]100%|| 3/3 [00:01<00:00,  1.54it/s]
2025-10-19 14:12:45,679 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4f1dd-7368ed0e03517edf578b26cb;c0fd5294-a056-498d-9c85-d595f5ae2368)
2025-10-19 14:12:45,684 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:12:45,693 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:12:45,699 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:12:45,701 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:12:45,704 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:12:45,707 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:12:46,192 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:46] Energy consumed for RAM : 0.000121 kWh. RAM Power : 38.0 W
2025-10-19 14:12:46,721 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:46] Delta energy consumed for CPU with cpu_load : 0.000056 kWh, power : 17.566374871454546 W
2025-10-19 14:12:46,726 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:46] Energy consumed for All CPU : 0.000056 kWh
2025-10-19 14:12:46,739 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:46] Energy consumed for all GPUs : 0.000166 kWh. Total GPU Power : 50.1996478912249 W
2025-10-19 14:12:46,749 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:12:46] 0.000343 kWh of electricity used since the beginning.
2025-10-19 14:12:46,752 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 1.9438, 'train_samples_per_second': 9.26, 'train_steps_per_second': 1.543, 'train_loss': 2.181854724884033, 'epoch': 1.0}
2025-10-19 14:12:46,755 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:12:46,757 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 14:12:46,759 - app.training.runpod_trainer - INFO - Training output: Final training loss: 2.1819
2025-10-19 14:12:46,762 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 14:12:46,764 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 14:12:46,767 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.000082 kg CO2
2025-10-19 14:12:46,769 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:12:46,770 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 14:12:47,656 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 14:12:48,041 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 14:12:48,547 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 14:12:49,303 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 14:12:50,047 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 14:12:50,808 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 14:12:53,204 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 14:12:53,953 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 14:12:54,701 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 14:12:55,402 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 14:12:58,887 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 14:12:59,647 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 14:12:59,659 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815
2025-10-19 14:12:59,662 - app.training.runpod_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815
2025-10-19 14:12:59,669 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_140815
2025-10-19 14:19:09,658 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909 added to queue with priority 0
2025-10-19 14:19:10,136 - app.training.runpod_trainer - INFO - Launching RunPod instance: runpod-gpu-20251019141910
2025-10-19 14:20:20,565 - app.training.runpod_trainer - INFO - Pod vsfok4a8a66mp1 launched successfully at 103.196.86.192:14801
2025-10-19 14:20:20,582 - app.training.gpu_queue_manager - INFO - Created new RunPod pod runpod-gpu-20251019141910
2025-10-19 14:20:20,598 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909 on runpod runpod-gpu-20251019141910
2025-10-19 14:20:20,618 - app.training.runpod_trainer - INFO - Starting training execution on pod vsfok4a8a66mp1
2025-10-19 14:20:20,621 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 14:20:39,399 - app.training.runpod_trainer - INFO - Attempting SSH connection to 103.196.86.192:14801 (attempt 1/10)
2025-10-19 14:20:39,419 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 14:20:39,513 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 14:20:39,692 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 14:20:39,698 - app.training.runpod_trainer - INFO - SSH connection established to 103.196.86.192:14801
2025-10-19 14:20:39,958 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 14:20:40,156 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 14:20:40,164 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 14:22:11,280 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 14:22:14,131 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /usr/local/lib/python3.10/dist-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
2025-10-19 14:22:14,148 - app.training.runpod_trainer - INFO - Training output: warn(
2025-10-19 14:22:14,851 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:22:14] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 14:22:14,913 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:14] [setup] RAM Tracking...
2025-10-19 14:22:14,919 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:14] [setup] CPU Tracking...
2025-10-19 14:22:16,083 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:22:16] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 14:22:16,088 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 14:22:16,095 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:22:16,106 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16] CPU Model on constant consumption mode: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:22:16,108 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:22:16] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 14:22:16,111 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16] [setup] GPU Tracking...
2025-10-19 14:22:16,114 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16] Tracking Nvidia GPU via pynvml
2025-10-19 14:22:16,116 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16] The below tracking methods have been set up:
2025-10-19 14:22:16,119 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 14:22:16,121 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 14:22:16,124 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 14:22:16,127 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:22:16,130 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16] >>> Tracker's metadata:
2025-10-19 14:22:16,131 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   Platform system: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
2025-10-19 14:22:16,134 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   Python version: 3.10.12
2025-10-19 14:22:16,136 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   CodeCarbon version: 3.0.7
2025-10-19 14:22:16,138 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   Available RAM : 503.700 GB
2025-10-19 14:22:16,140 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   CPU count: 128 thread(s) in 2 physical CPU(s)
2025-10-19 14:22:16,141 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   CPU model: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:22:16,143 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   GPU count: 1
2025-10-19 14:22:16,144 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:16]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 14:22:19,253 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:19] Emissions data (if any) will be saved to file /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909/emissions.csv
2025-10-19 14:22:20,982 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 14:22:25,691 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:22:25,700 - app.training.runpod_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909
2025-10-19 14:22:25,709 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 14:22:25,711 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 14:22:25,717 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:22:25,721 - app.training.runpod_trainer - INFO - Training output: Loaded 21 training examples
2025-10-19 14:22:25,725 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 14:22:25,728 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 14:22:25,732 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 14:22:25,733 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 14:22:25,735 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 14:22:25,737 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 14:22:25,738 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 14:22:25,739 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 14:22:25,740 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:22:25,742 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:22:25,743 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:22:25,744 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:22:25,746 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,748 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 14:22:25,749 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:22:25,750 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:22:25,751 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 14:22:25,752 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 14:22:25,754 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,755 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:22:25,756 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:22:25,757 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,758 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,760 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:22:25,763 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 14:22:25,764 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,766 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 14:22:25,766 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:22:25,768 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 14:22:25,770 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 14:22:25,771 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,772 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,773 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,774 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,775 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,776 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,778 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,779 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,780 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,781 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,782 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,783 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,784 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,785 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,786 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,790 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,791 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,792 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,793 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,794 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,794 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,796 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,797 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,797 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,798 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,799 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,800 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,801 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,802 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,803 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,804 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,804 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,805 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,806 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,807 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,808 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,809 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,811 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,812 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,813 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,815 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,816 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,817 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,820 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,821 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,821 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,822 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,823 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,824 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,825 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,826 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,826 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,827 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,828 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,829 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,830 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,831 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,832 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,832 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,834 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,835 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,836 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,837 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,838 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,839 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,840 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,841 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,842 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,842 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,844 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,844 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,845 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,846 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,847 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,848 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,849 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,850 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,850 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,852 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,853 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,854 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,855 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,856 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,857 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,858 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,859 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,860 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,861 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,862 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,863 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,864 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,866 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,866 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,867 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,868 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,869 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,870 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,871 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,873 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,875 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,876 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,877 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,878 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,879 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,880 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,881 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,882 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,884 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,885 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,887 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,888 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,889 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,890 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,891 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,892 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,894 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,895 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,896 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,897 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,898 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,899 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,900 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,901 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,902 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,905 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,913 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,915 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,918 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,918 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,920 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,927 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,932 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,933 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,934 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,935 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,936 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,937 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,938 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,939 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,940 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,941 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,942 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,943 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,944 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,945 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,946 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,947 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,948 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,949 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,949 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,950 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,951 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,952 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,954 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,955 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,955 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,956 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,957 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,958 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,959 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,960 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,960 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,961 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,962 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,963 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,965 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,966 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,966 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,967 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,968 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,969 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,970 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,971 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,972 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,973 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,974 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,975 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,976 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,977 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,978 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,979 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,980 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,981 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,982 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,982 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,983 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,984 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,985 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,986 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,987 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,988 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,989 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,990 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,991 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,992 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,993 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,994 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,995 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,996 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,997 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,998 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:25,998 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:25,999 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,000 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,001 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,002 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,003 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,003 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,004 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,005 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,006 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,007 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,008 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,009 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,010 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,011 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,012 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,013 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,014 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,015 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,016 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,017 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,018 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:22:26,019 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:22:26,020 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 14:22:26,020 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 14:22:26,021 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 14:22:26,022 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 286.12 examples/s]
2025-10-19 14:22:26,023 - app.training.runpod_trainer - INFO - Training output: /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 14:22:26,024 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 14:22:26,026 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 14:22:26,026 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 14:22:26,095 - app.training.runpod_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-19 14:22:26,096 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 14:22:26,098 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:22:26,127 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/9 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 14:22:30,133 - app.training.runpod_trainer - INFO - Training output: 11%|         | 1/9 [00:00<00:07,  1.05it/s] 22%|       | 2/9 [00:01<00:04,  1.45it/s] 33%|      | 3/9 [00:01<00:02,  2.30it/s] 44%|     | 4/9 [00:02<00:02,  2.20it/s] 56%|    | 5/9 [00:02<00:01,  2.11it/s] 67%|   | 6/9 [00:02<00:01,  2.80it/s] 78%|  | 7/9 [00:03<00:00,  2.34it/s] 89%| | 8/9 [00:03<00:00,  2.12it/s]100%|| 9/9 [00:03<00:00,  2.72it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4f426-5a69bde45b9272270aadbef0;747ff3b2-abe0-42cd-b9e9-3acd1ccc7925)
2025-10-19 14:22:30,146 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:22:30,156 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:22:30,161 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:22:30,165 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:22:30,167 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:22:30,168 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:22:30,643 - app.training.runpod_trainer - INFO - Training output: 100%|| 9/9 [00:04<00:00,  2.72it/s]100%|| 9/9 [00:04<00:00,  1.98it/s]
2025-10-19 14:22:30,693 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4f426-71171fc42d68b94135004c94;89ccf1ca-4f9a-4bc3-b996-6ee88deea43c)
2025-10-19 14:22:30,697 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:22:30,700 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:22:30,702 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:22:30,704 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:22:30,706 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:22:30,708 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:22:31,224 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:31] Energy consumed for RAM : 0.000233 kWh. RAM Power : 70.0 W
2025-10-19 14:22:31,674 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:31] Delta energy consumed for CPU with cpu_load : 0.000187 kWh, power : 56.12791742599999 W
2025-10-19 14:22:31,677 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:31] Energy consumed for All CPU : 0.000187 kWh
2025-10-19 14:22:31,681 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:31] Energy consumed for all GPUs : 0.000367 kWh. Total GPU Power : 105.8388380319614 W
2025-10-19 14:22:31,687 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:22:31] 0.000786 kWh of electricity used since the beginning.
2025-10-19 14:22:31,691 - app.training.runpod_trainer - INFO - Training output: [codecarbon ERROR @ 14:22:31] Region:  not found for Country with ISO CODE : USA
2025-10-19 14:22:31,696 - app.training.runpod_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-19 14:22:31,700 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-19 14:22:31,703 - app.training.runpod_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-19 14:22:31,705 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-19 14:22:31,708 - app.training.runpod_trainer - INFO - Training output: raise ValueError(
2025-10-19 14:22:31,709 - app.training.runpod_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-19 14:22:31,711 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:22:31] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-19 14:22:31,713 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 4.5449, 'train_samples_per_second': 11.881, 'train_steps_per_second': 1.98, 'train_loss': 1.5116259256998699, 'epoch': 3.0}
2025-10-19 14:22:31,715 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:22:31,716 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 14:22:31,719 - app.training.runpod_trainer - INFO - Training output: Final training loss: 1.5116
2025-10-19 14:22:31,721 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 14:22:31,723 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 14:22:31,725 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.000290 kg CO2
2025-10-19 14:22:31,727 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:22:31,729 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 14:22:32,866 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 14:22:32,997 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 14:22:33,142 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 14:22:33,342 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 14:22:33,521 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 14:22:33,718 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 14:22:35,228 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 14:22:35,423 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 14:22:35,648 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 14:22:35,892 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 14:22:39,671 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 14:22:39,878 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 14:22:39,879 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909
2025-10-19 14:22:39,881 - app.training.runpod_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909
2025-10-19 14:22:39,883 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_141909
2025-10-19 14:23:52,275 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_142352 added to queue with priority 0
2025-10-19 14:28:29,956 - app.main - INFO - Starting Understudy API...
2025-10-19 14:28:29,982 - app.main - INFO - Database initialized
2025-10-19 14:28:30,037 - app.main - INFO - Initializing GPU training queue...
2025-10-19 14:28:30,038 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 14:28:30,047 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 14:28:30,048 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 14:28:30,051 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 14:28:30,066 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 14:28:30,097 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 14:28:30,213 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 14:28:30,218 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 14:28:30,572 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 14:28:30,574 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 14:28:31,019 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 14:28:31,020 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 14:28:31,021 - app.main - INFO - Cloud GPU training system ready
2025-10-19 14:28:35,117 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_142835 added to queue with priority 0
2025-10-19 14:42:19,515 - app.main - INFO - Starting Understudy API...
2025-10-19 14:42:19,544 - app.main - INFO - Database initialized
2025-10-19 14:42:19,603 - app.main - INFO - Initializing GPU training queue...
2025-10-19 14:42:19,604 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 14:42:19,614 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 14:42:19,614 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 14:42:19,615 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 14:42:19,616 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 14:42:19,617 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 14:42:19,700 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 14:42:19,703 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 14:42:19,947 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 14:42:19,949 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 14:42:20,494 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 14:42:20,503 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 14:42:20,508 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 14:42:20,515 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 14:42:21,007 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 14:42:21,011 - app.training.gpu_queue_manager - INFO - Checking 1 existing RunPod pods for reuse eligibility
2025-10-19 14:42:21,021 - app.training.gpu_queue_manager - ERROR - Failed to check existing RunPod pods: unsupported operand type(s) for +: 'int' and 'str'
2025-10-19 14:42:21,024 - app.main - INFO - Cloud GPU training system ready
2025-10-19 14:44:34,757 - app.main - INFO - Shutting down Understudy API...
2025-10-19 14:46:29,567 - app.main - INFO - Starting Understudy API...
2025-10-19 14:46:29,602 - app.main - INFO - Database initialized
2025-10-19 14:46:29,655 - app.main - INFO - Initializing GPU training queue...
2025-10-19 14:46:29,657 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 14:46:29,672 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 14:46:29,674 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 14:46:29,674 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 14:46:29,676 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 14:46:29,677 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 14:46:29,777 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 14:46:29,781 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 14:46:30,048 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 14:46:30,051 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 14:46:30,558 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 14:46:30,569 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 14:46:30,577 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 14:46:30,581 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 14:46:30,970 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 14:46:30,976 - app.training.gpu_queue_manager - INFO - Checking 1 existing RunPod pods for reuse eligibility
2025-10-19 14:46:30,988 - app.training.gpu_queue_manager - INFO - Found existing RunPod pod: runpod-gpu-20251019141910 (vsfok4a8a66mp1)
2025-10-19 14:46:30,994 - app.training.gpu_queue_manager - INFO - Discovered 1 existing RunPod pods available for reuse
2025-10-19 14:46:30,996 - app.main - INFO - Cloud GPU training system ready
2025-10-19 14:46:46,940 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646 added to queue with priority 0
2025-10-19 14:46:50,161 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 14:46:50,172 - app.training.gpu_queue_manager - INFO - Checking for reusable RunPod pods among 1 active VMs
2025-10-19 14:46:50,174 - app.training.gpu_queue_manager - INFO - Reusing RunPod pod vsfok4a8a66mp1 (runpod-gpu-20251019141910)
2025-10-19 14:46:50,179 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646 on runpod runpod-gpu-20251019141910
2025-10-19 14:46:50,181 - app.training.runpod_trainer - INFO - Starting training execution on pod vsfok4a8a66mp1
2025-10-19 14:46:50,182 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 14:46:50,183 - app.training.runpod_trainer - INFO - Attempting SSH connection to 103.196.86.192:14801 (attempt 1/10)
2025-10-19 14:46:50,184 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 14:46:50,330 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 14:46:50,500 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 14:46:50,501 - app.training.runpod_trainer - INFO - SSH connection established to 103.196.86.192:14801
2025-10-19 14:46:50,768 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 14:46:51,010 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 14:46:51,019 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 14:47:39,477 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 14:47:43,055 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:47:42] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 14:47:43,064 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:43] [setup] RAM Tracking...
2025-10-19 14:47:43,075 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:43] [setup] CPU Tracking...
2025-10-19 14:47:44,282 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:47:44] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 14:47:44,286 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 14:47:44,291 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:47:44,296 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44] CPU Model on constant consumption mode: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:47:44,300 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:47:44] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 14:47:44,301 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44] [setup] GPU Tracking...
2025-10-19 14:47:44,302 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44] Tracking Nvidia GPU via pynvml
2025-10-19 14:47:44,303 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44] The below tracking methods have been set up:
2025-10-19 14:47:44,304 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 14:47:44,305 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 14:47:44,306 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 14:47:44,307 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:47:44,308 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44] >>> Tracker's metadata:
2025-10-19 14:47:44,309 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   Platform system: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
2025-10-19 14:47:44,310 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   Python version: 3.10.12
2025-10-19 14:47:44,311 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   CodeCarbon version: 3.0.7
2025-10-19 14:47:44,312 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   Available RAM : 503.700 GB
2025-10-19 14:47:44,313 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   CPU count: 128 thread(s) in 2 physical CPU(s)
2025-10-19 14:47:44,314 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   CPU model: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:47:44,314 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   GPU count: 1
2025-10-19 14:47:44,315 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:44]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 14:47:47,360 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:47] Emissions data (if any) will be saved to file /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646/emissions.csv
2025-10-19 14:47:48,380 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 14:47:50,945 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:47:50,961 - app.training.runpod_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646
2025-10-19 14:47:50,966 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 14:47:50,968 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 14:47:50,971 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:47:50,973 - app.training.runpod_trainer - INFO - Training output: Loaded 21 training examples
2025-10-19 14:47:50,975 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 14:47:50,978 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 14:47:50,980 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 14:47:50,982 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 14:47:50,984 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 14:47:50,985 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 14:47:50,987 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 14:47:50,989 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 14:47:50,991 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:47:50,993 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:47:50,994 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:47:50,996 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:47:50,997 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:50,998 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 14:47:51,000 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:47:51,001 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:47:51,002 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 14:47:51,003 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 14:47:51,004 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:51,005 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:47:51,006 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:47:51,007 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:51,008 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:51,009 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:47:51,010 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 14:47:51,011 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:51,012 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 14:47:51,013 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:47:51,014 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 14:47:51,015 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 14:47:51,015 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,016 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,017 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,018 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,020 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,020 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,021 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,022 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,023 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,024 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,024 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,025 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,026 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,027 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,027 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,028 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,029 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,030 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,031 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,032 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,032 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,034 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,035 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,036 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,037 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,038 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,041 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,042 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,043 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,044 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,045 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,046 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,047 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,049 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,050 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,052 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,052 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,053 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,055 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,055 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,056 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,057 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,058 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,059 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,060 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,061 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,062 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,063 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,064 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,065 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,066 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,068 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,069 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,070 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,071 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,072 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,074 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,075 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,077 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,080 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,085 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,089 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,092 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,093 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,094 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,096 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,097 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,098 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,099 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,100 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,101 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,102 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,104 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,104 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,105 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,106 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,107 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,107 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,108 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,109 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,110 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,110 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,111 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,112 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,113 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,114 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,115 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,116 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,117 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,118 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,119 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,119 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,121 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,121 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,122 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,123 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,124 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,125 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,125 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,126 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,127 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,128 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,129 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,130 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,131 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,131 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,133 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,134 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,135 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,137 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,138 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,139 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,140 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,141 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,142 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,143 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,144 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,145 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,146 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,146 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,147 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,148 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,149 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,150 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,151 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,152 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,152 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,153 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,154 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,155 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,156 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,157 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,157 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,158 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,159 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,160 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,162 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,162 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,163 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,164 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,165 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,165 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,166 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,167 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,168 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,169 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,170 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,170 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,171 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,172 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,173 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,174 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,174 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,175 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,176 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,177 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,178 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,178 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,180 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,180 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,181 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,182 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,183 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,184 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,185 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,185 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,186 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,187 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,188 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,189 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,191 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,192 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,192 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,194 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,196 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,197 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,198 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,199 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,200 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,201 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,203 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,204 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,205 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,205 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,206 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,207 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,208 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,209 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,210 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,226 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,254 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,254 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,255 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,256 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,257 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,272 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,274 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,275 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,275 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,276 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,277 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,278 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,280 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,280 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,281 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,282 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,283 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,284 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,285 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,286 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,286 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,287 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,288 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,289 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,289 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,290 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,291 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,292 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,293 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,294 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,295 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,295 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,296 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:47:51,298 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:47:51,299 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 14:47:51,299 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 14:47:51,300 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 14:47:51,301 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 2484.78 examples/s]
2025-10-19 14:47:51,302 - app.training.runpod_trainer - INFO - Training output: /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 14:47:51,303 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 14:47:51,303 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 14:47:51,305 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 14:47:51,305 - app.training.runpod_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-19 14:47:51,306 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 14:47:51,307 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:47:51,308 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/9 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 14:47:54,978 - app.training.runpod_trainer - INFO - Training output: 11%|         | 1/9 [00:00<00:06,  1.16it/s] 22%|       | 2/9 [00:01<00:04,  1.56it/s] 33%|      | 3/9 [00:01<00:02,  2.44it/s] 44%|     | 4/9 [00:01<00:02,  2.27it/s] 56%|    | 5/9 [00:02<00:01,  2.20it/s] 67%|   | 6/9 [00:02<00:01,  2.90it/s] 78%|  | 7/9 [00:03<00:00,  2.57it/s] 89%| | 8/9 [00:03<00:00,  2.38it/s]100%|| 9/9 [00:03<00:00,  3.01it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa1a-4300af347cf36f3a4b979254;5a208e7b-aa06-44bc-8538-694df6e6f56e)
2025-10-19 14:47:54,982 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:47:54,985 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:47:54,987 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:47:54,988 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:47:54,991 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:47:54,993 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:47:55,755 - app.training.runpod_trainer - INFO - Training output: 100%|| 9/9 [00:04<00:00,  3.01it/s]100%|| 9/9 [00:04<00:00,  2.02it/s]
2025-10-19 14:47:55,768 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa1b-116e625a7583a0ec6a3e6557;ccb0560b-9839-499b-afc8-15329dbd36dd)
2025-10-19 14:47:55,769 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:47:55,771 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:47:55,772 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:47:55,774 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:47:55,776 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:47:55,778 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:47:56,571 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:56] Energy consumed for RAM : 0.000178 kWh. RAM Power : 70.0 W
2025-10-19 14:47:57,085 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:56] Delta energy consumed for CPU with cpu_load : 0.000142 kWh, power : 56.04572556800001 W
2025-10-19 14:47:57,088 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:56] Energy consumed for All CPU : 0.000142 kWh
2025-10-19 14:47:57,091 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:56] Energy consumed for all GPUs : 0.000324 kWh. Total GPU Power : 120.99951402371887 W
2025-10-19 14:47:57,093 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:47:56] 0.000644 kWh of electricity used since the beginning.
2025-10-19 14:47:57,095 - app.training.runpod_trainer - INFO - Training output: [codecarbon ERROR @ 14:47:56] Region:  not found for Country with ISO CODE : USA
2025-10-19 14:47:57,097 - app.training.runpod_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-19 14:47:57,099 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-19 14:47:57,100 - app.training.runpod_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-19 14:47:57,102 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-19 14:47:57,103 - app.training.runpod_trainer - INFO - Training output: raise ValueError(
2025-10-19 14:47:57,104 - app.training.runpod_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-19 14:47:57,105 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:47:56] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-19 14:47:57,106 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 4.4607, 'train_samples_per_second': 12.106, 'train_steps_per_second': 2.018, 'train_loss': 1.516972753736708, 'epoch': 3.0}
2025-10-19 14:47:57,107 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:47:57,109 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 14:47:57,110 - app.training.runpod_trainer - INFO - Training output: Final training loss: 1.5170
2025-10-19 14:47:57,112 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 14:47:57,114 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 14:47:57,115 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.000238 kg CO2
2025-10-19 14:47:57,116 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:47:57,117 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 14:47:58,004 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 14:47:58,136 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 14:47:58,254 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 14:47:58,455 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 14:47:58,649 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 14:47:58,856 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 14:47:59,823 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 14:48:00,011 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 14:48:00,264 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 14:48:00,455 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 14:48:02,024 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 14:48:02,218 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 14:48:02,220 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646
2025-10-19 14:48:02,222 - app.training.runpod_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646
2025-10-19 14:48:02,226 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144646
2025-10-19 14:48:08,384 - app.training.gpu_queue_manager - INFO - Marked runpod instance runpod-gpu-20251019141910 as idle for potential reuse
2025-10-19 14:48:46,606 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846 added to queue with priority 0
2025-10-19 14:48:48,916 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 14:48:48,924 - app.training.gpu_queue_manager - INFO - Checking for reusable RunPod pods among 1 active VMs
2025-10-19 14:48:48,927 - app.training.gpu_queue_manager - INFO - Reusing RunPod pod vsfok4a8a66mp1 (runpod-gpu-20251019141910)
2025-10-19 14:48:48,933 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846 on runpod runpod-gpu-20251019141910
2025-10-19 14:48:48,940 - app.training.runpod_trainer - INFO - Starting training execution on pod vsfok4a8a66mp1
2025-10-19 14:48:48,942 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 14:48:48,944 - app.training.runpod_trainer - INFO - Attempting SSH connection to 103.196.86.192:14801 (attempt 1/10)
2025-10-19 14:48:48,946 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 14:48:49,018 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 14:48:49,197 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 14:48:49,200 - app.training.runpod_trainer - INFO - SSH connection established to 103.196.86.192:14801
2025-10-19 14:48:49,447 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 14:48:49,666 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 14:48:49,668 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 14:48:52,546 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 14:48:56,271 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:48:56] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 14:48:56,276 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:56] [setup] RAM Tracking...
2025-10-19 14:48:56,282 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:56] [setup] CPU Tracking...
2025-10-19 14:48:57,413 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:48:57] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 14:48:57,418 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 14:48:57,425 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:48:57,428 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57] CPU Model on constant consumption mode: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:48:57,431 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:48:57] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 14:48:57,432 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57] [setup] GPU Tracking...
2025-10-19 14:48:57,434 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57] Tracking Nvidia GPU via pynvml
2025-10-19 14:48:57,437 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57] The below tracking methods have been set up:
2025-10-19 14:48:57,439 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 14:48:57,440 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 14:48:57,442 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 14:48:57,444 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:48:57,446 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57] >>> Tracker's metadata:
2025-10-19 14:48:57,448 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   Platform system: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
2025-10-19 14:48:57,450 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   Python version: 3.10.12
2025-10-19 14:48:57,452 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   CodeCarbon version: 3.0.7
2025-10-19 14:48:57,454 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   Available RAM : 503.700 GB
2025-10-19 14:48:57,455 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   CPU count: 128 thread(s) in 2 physical CPU(s)
2025-10-19 14:48:57,457 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   CPU model: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:48:57,459 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   GPU count: 1
2025-10-19 14:48:57,462 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:48:57]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 14:49:00,571 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:00] Emissions data (if any) will be saved to file /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846/emissions.csv
2025-10-19 14:49:01,527 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 14:49:04,129 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:49:04,136 - app.training.runpod_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846
2025-10-19 14:49:04,147 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 14:49:04,148 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 14:49:04,149 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:49:04,151 - app.training.runpod_trainer - INFO - Training output: Loaded 21 training examples
2025-10-19 14:49:04,152 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 14:49:04,153 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 14:49:04,154 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 14:49:04,155 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 14:49:04,156 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 14:49:04,157 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 14:49:04,158 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 14:49:04,158 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 14:49:04,160 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:49:04,160 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:49:04,161 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:49:04,162 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:49:04,163 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,163 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 14:49:04,164 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:49:04,193 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:49:04,193 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 14:49:04,194 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 14:49:04,196 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,198 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:49:04,204 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:49:04,205 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,206 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,207 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:49:04,208 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 14:49:04,209 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,209 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 14:49:04,210 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:49:04,211 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 14:49:04,212 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 14:49:04,213 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,214 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,215 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,216 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,216 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,217 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,218 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,219 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,220 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,220 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,221 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,222 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,223 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,224 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,224 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,225 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,226 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,227 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,228 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,229 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,229 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,230 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,232 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,232 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,233 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,234 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,235 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,236 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,237 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,238 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,238 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,239 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,240 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,241 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,241 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,242 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,243 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,244 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,245 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,246 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,247 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,248 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,248 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,249 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,250 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,251 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,252 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,253 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,254 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,254 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,255 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,256 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,257 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,258 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,259 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,259 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,260 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,261 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,262 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,262 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,263 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,264 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,265 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,266 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,267 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,267 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,268 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,269 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,270 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,271 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,272 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,273 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,273 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,274 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,275 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,276 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,277 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,278 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,279 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,279 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,280 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,281 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,282 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,283 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,284 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,285 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,285 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,286 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,288 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,288 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,289 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,290 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,291 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,292 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,292 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,293 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,294 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,295 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,296 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,297 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,298 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,298 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,299 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,300 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,301 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,302 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,303 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,303 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,304 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,305 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,306 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,307 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,308 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,309 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,310 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,310 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,311 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,312 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,313 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,313 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,314 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,315 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,316 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,317 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,317 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,318 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,319 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,320 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,320 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,321 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,322 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,323 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,324 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,325 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,326 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,327 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,327 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,328 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,329 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,330 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,331 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,331 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,332 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,333 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,334 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,334 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,335 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,336 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,337 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,338 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,338 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,339 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,340 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,340 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,341 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,342 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,343 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,344 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,344 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,346 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,347 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,347 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,348 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,349 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,350 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,350 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,351 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,352 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,353 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,353 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,354 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,355 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,356 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,356 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,357 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,358 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,359 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,360 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,361 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,361 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,362 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,363 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,364 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,365 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,365 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,366 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,367 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,368 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,369 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,369 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,370 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,371 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,372 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,373 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,373 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,374 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,375 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,376 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,377 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,378 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,378 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,379 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,380 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,381 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,381 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,382 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,383 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,384 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,384 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,385 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,386 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,387 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,388 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,389 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,389 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,390 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,391 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,392 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,392 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,393 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,394 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,395 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,396 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:49:04,397 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:49:04,397 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 14:49:04,398 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 14:49:04,399 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 14:49:04,400 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 2603.08 examples/s]
2025-10-19 14:49:04,400 - app.training.runpod_trainer - INFO - Training output: /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 14:49:04,401 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 14:49:04,402 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 14:49:04,403 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 14:49:04,484 - app.training.runpod_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-19 14:49:04,485 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 14:49:04,486 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:49:04,514 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/9 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 14:49:08,184 - app.training.runpod_trainer - INFO - Training output: 11%|         | 1/9 [00:00<00:06,  1.16it/s] 22%|       | 2/9 [00:01<00:04,  1.57it/s] 33%|      | 3/9 [00:01<00:02,  2.47it/s] 44%|     | 4/9 [00:01<00:02,  2.30it/s] 56%|    | 5/9 [00:02<00:01,  2.23it/s] 67%|   | 6/9 [00:02<00:01,  2.91it/s] 78%|  | 7/9 [00:03<00:00,  2.59it/s] 89%| | 8/9 [00:03<00:00,  2.41it/s]100%|| 9/9 [00:03<00:00,  3.04it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa64-7c0c0d9411aa52f520feed10;ae8f92b3-fbfb-47f6-989b-5f8ac8452854)
2025-10-19 14:49:08,190 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:49:08,198 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:49:08,206 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:49:08,212 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:49:08,214 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:49:08,216 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:49:08,933 - app.training.runpod_trainer - INFO - Training output: 100%|| 9/9 [00:04<00:00,  3.04it/s]100%|| 9/9 [00:04<00:00,  2.02it/s]
2025-10-19 14:49:08,995 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa64-252852ca55d0ebc34876c7da;db3eca2b-1f16-44f3-915a-e1f9e7a30396)
2025-10-19 14:49:09,001 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:49:09,008 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:49:09,017 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:49:09,021 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:49:09,023 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:49:09,025 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:49:09,785 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:09] Energy consumed for RAM : 0.000178 kWh. RAM Power : 70.0 W
2025-10-19 14:49:10,204 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:10] Delta energy consumed for CPU with cpu_load : 0.000143 kWh, power : 56.03939717600002 W
2025-10-19 14:49:10,208 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:10] Energy consumed for All CPU : 0.000143 kWh
2025-10-19 14:49:10,212 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:10] Energy consumed for all GPUs : 0.000324 kWh. Total GPU Power : 120.6840423726413 W
2025-10-19 14:49:10,218 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:10] 0.000645 kWh of electricity used since the beginning.
2025-10-19 14:49:10,222 - app.training.runpod_trainer - INFO - Training output: [codecarbon ERROR @ 14:49:10] Region:  not found for Country with ISO CODE : USA
2025-10-19 14:49:10,224 - app.training.runpod_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-19 14:49:10,226 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-19 14:49:10,227 - app.training.runpod_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-19 14:49:10,229 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-19 14:49:10,231 - app.training.runpod_trainer - INFO - Training output: raise ValueError(
2025-10-19 14:49:10,232 - app.training.runpod_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-19 14:49:10,235 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:49:10] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-19 14:49:10,236 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 4.4454, 'train_samples_per_second': 12.147, 'train_steps_per_second': 2.025, 'train_loss': 1.508129013909234, 'epoch': 3.0}
2025-10-19 14:49:10,237 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:49:10,238 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 14:49:10,239 - app.training.runpod_trainer - INFO - Training output: Final training loss: 1.5081
2025-10-19 14:49:10,241 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 14:49:10,242 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 14:49:10,244 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.000238 kg CO2
2025-10-19 14:49:10,245 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:49:10,247 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 14:49:11,838 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 14:49:11,981 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 14:49:12,110 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 14:49:12,343 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 14:49:12,554 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 14:49:12,742 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 14:49:14,151 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 14:49:14,364 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 14:49:14,596 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 14:49:14,806 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 14:49:16,244 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 14:49:16,428 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 14:49:16,430 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846
2025-10-19 14:49:16,432 - app.training.runpod_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846
2025-10-19 14:49:16,434 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144846
2025-10-19 14:49:16,451 - app.training.gpu_queue_manager - INFO - Marked runpod instance runpod-gpu-20251019141910 as idle for potential reuse
2025-10-19 14:49:45,952 - app.training.gpu_queue_manager - INFO - Training job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945 added to queue with priority 0
2025-10-19 14:49:46,780 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 14:49:46,787 - app.training.gpu_queue_manager - INFO - Checking for reusable RunPod pods among 1 active VMs
2025-10-19 14:49:46,791 - app.training.gpu_queue_manager - INFO - Reusing RunPod pod vsfok4a8a66mp1 (runpod-gpu-20251019141910)
2025-10-19 14:49:46,796 - app.training.gpu_queue_manager - INFO - Starting training for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945 on runpod runpod-gpu-20251019141910
2025-10-19 14:49:46,797 - app.training.runpod_trainer - INFO - Starting training execution on pod vsfok4a8a66mp1
2025-10-19 14:49:46,798 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 14:49:46,799 - app.training.runpod_trainer - INFO - Attempting SSH connection to 103.196.86.192:14801 (attempt 1/10)
2025-10-19 14:49:46,802 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 14:49:46,881 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 14:49:47,071 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 14:49:47,078 - app.training.runpod_trainer - INFO - SSH connection established to 103.196.86.192:14801
2025-10-19 14:49:47,341 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 14:49:47,536 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 14:49:47,541 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 14:49:50,413 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 14:49:54,028 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:49:53] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 14:49:54,039 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:53] [setup] RAM Tracking...
2025-10-19 14:49:54,049 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:53] [setup] CPU Tracking...
2025-10-19 14:49:55,258 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:49:55] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 14:49:55,264 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 14:49:55,276 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:49:55,281 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55] CPU Model on constant consumption mode: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:49:55,284 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:49:55] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 14:49:55,287 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55] [setup] GPU Tracking...
2025-10-19 14:49:55,288 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55] Tracking Nvidia GPU via pynvml
2025-10-19 14:49:55,289 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55] The below tracking methods have been set up:
2025-10-19 14:49:55,290 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 14:49:55,292 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 14:49:55,293 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 14:49:55,294 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:49:55,295 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55] >>> Tracker's metadata:
2025-10-19 14:49:55,295 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   Platform system: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
2025-10-19 14:49:55,296 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   Python version: 3.10.12
2025-10-19 14:49:55,297 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   CodeCarbon version: 3.0.7
2025-10-19 14:49:55,298 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   Available RAM : 503.700 GB
2025-10-19 14:49:55,299 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   CPU count: 128 thread(s) in 2 physical CPU(s)
2025-10-19 14:49:55,300 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   CPU model: AMD EPYC 75F3 32-Core Processor
2025-10-19 14:49:55,301 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   GPU count: 1
2025-10-19 14:49:55,301 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:55]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 14:49:58,298 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:49:58] Emissions data (if any) will be saved to file /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945/emissions.csv
2025-10-19 14:49:59,347 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 14:50:01,914 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:50:01,920 - app.training.runpod_trainer - INFO - Training output: Starting training job: b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945
2025-10-19 14:50:01,933 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 14:50:01,935 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 14:50:01,937 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:50:01,940 - app.training.runpod_trainer - INFO - Training output: Loaded 21 training examples
2025-10-19 14:50:01,943 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 14:50:01,946 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 14:50:01,948 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 14:50:01,949 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 14:50:01,951 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 14:50:01,953 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 14:50:01,955 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 14:50:01,957 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 14:50:01,958 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:50:01,960 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:50:01,962 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 14:50:01,963 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 14:50:01,965 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,967 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 14:50:01,969 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:50:01,971 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 14:50:01,972 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 14:50:01,974 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 14:50:01,975 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,977 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:50:01,978 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:50:01,979 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,981 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,982 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 14:50:01,983 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 14:50:01,985 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,986 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 14:50:01,987 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 14:50:01,988 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 14:50:01,989 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 14:50:01,989 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,990 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:01,991 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,992 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:01,993 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,994 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:01,995 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,996 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:01,997 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,997 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:01,998 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:01,999 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,000 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,001 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,002 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,003 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,004 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,004 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,005 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,006 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,007 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,008 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,009 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,009 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,010 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,011 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,012 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,013 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,013 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,014 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,015 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,016 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,017 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,018 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,019 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,020 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,021 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,022 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,022 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,023 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,025 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,026 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,027 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,028 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,029 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,030 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,031 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,031 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,032 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,033 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,034 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,035 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,036 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,036 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,037 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,038 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,039 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,040 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,040 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,041 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,042 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,043 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,044 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,045 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,046 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,047 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,047 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,048 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,049 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,050 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,050 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,051 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,051 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,052 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,053 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,054 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,054 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,055 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,056 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,057 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,058 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,059 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,059 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,060 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,061 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,062 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,063 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,064 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,064 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,065 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,066 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,067 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,068 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,069 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,069 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,070 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,071 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,072 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,072 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,073 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,074 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,075 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,075 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,105 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,106 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,107 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,108 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,112 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,113 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,115 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,116 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,117 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,118 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,119 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,120 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,120 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,121 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,122 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,123 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,124 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,125 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,125 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,126 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,127 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,128 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,129 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,130 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,131 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,131 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,133 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,133 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,134 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,135 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,136 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,136 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,137 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,138 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,139 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,140 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,141 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,141 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,142 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,143 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,144 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,144 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,147 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,147 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,148 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,149 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,150 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,151 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,152 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,153 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,154 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,154 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,155 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,156 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,157 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,157 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,158 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,159 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,160 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,161 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,162 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,163 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,164 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,165 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,167 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,167 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,168 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,169 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,170 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,171 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,172 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,173 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,173 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,174 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,175 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,176 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,177 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,177 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,178 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,179 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,180 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,181 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,181 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,182 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,183 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,184 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,185 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,186 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,186 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,187 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,188 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,189 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,190 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,190 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,191 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,192 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,193 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,194 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,194 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,195 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,196 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,197 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,198 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,199 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,200 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,201 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,202 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,203 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,204 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,205 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,206 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,207 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,208 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,209 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,210 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,211 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,212 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,212 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,213 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,214 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 14:50:02,215 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 14:50:02,216 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 14:50:02,217 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 14:50:02,218 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 14:50:02,219 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/21 [00:00<?, ? examples/s]Map: 100%|| 21/21 [00:00<00:00, 2506.48 examples/s]
2025-10-19 14:50:02,219 - app.training.runpod_trainer - INFO - Training output: /workspace/training/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 14:50:02,220 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 14:50:02,221 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 14:50:02,222 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 14:50:02,263 - app.training.runpod_trainer - INFO - Training output: Train samples: 18, Eval samples: 3
2025-10-19 14:50:02,264 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 14:50:02,265 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:50:02,293 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/9 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 14:50:06,045 - app.training.runpod_trainer - INFO - Training output: 11%|         | 1/9 [00:00<00:06,  1.16it/s] 22%|       | 2/9 [00:01<00:04,  1.56it/s] 33%|      | 3/9 [00:01<00:02,  2.44it/s] 44%|     | 4/9 [00:01<00:02,  2.26it/s] 56%|    | 5/9 [00:02<00:01,  2.18it/s] 67%|   | 6/9 [00:02<00:01,  2.83it/s] 78%|  | 7/9 [00:03<00:00,  2.51it/s] 89%| | 8/9 [00:03<00:00,  2.32it/s]100%|| 9/9 [00:03<00:00,  2.95it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa9e-34c3e5410ae45f1e607ed69c;dac27a41-c06f-4834-9220-8b405fcaa8e9)
2025-10-19 14:50:06,054 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:50:06,062 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:50:06,065 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:50:06,067 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:50:06,069 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:50:06,071 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:50:06,772 - app.training.runpod_trainer - INFO - Training output: 100%|| 9/9 [00:04<00:00,  2.95it/s]100%|| 9/9 [00:04<00:00,  1.99it/s]
2025-10-19 14:50:06,830 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4fa9e-3c7540284516f43556a644cc;af22366f-15e3-42ce-be33-0a3740b41b97)
2025-10-19 14:50:06,834 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 14:50:06,837 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 14:50:06,841 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 14:50:06,845 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:50:06,848 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 14:50:06,852 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 14:50:07,535 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:50:07] Energy consumed for RAM : 0.000179 kWh. RAM Power : 70.0 W
2025-10-19 14:50:08,045 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:50:07] Delta energy consumed for CPU with cpu_load : 0.000143 kWh, power : 56.055159776000025 W
2025-10-19 14:50:08,046 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:50:07] Energy consumed for All CPU : 0.000143 kWh
2025-10-19 14:50:08,048 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:50:07] Energy consumed for all GPUs : 0.000327 kWh. Total GPU Power : 121.4703284523989 W
2025-10-19 14:50:08,050 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 14:50:07] 0.000650 kWh of electricity used since the beginning.
2025-10-19 14:50:08,051 - app.training.runpod_trainer - INFO - Training output: [codecarbon ERROR @ 14:50:07] Region:  not found for Country with ISO CODE : USA
2025-10-19 14:50:08,053 - app.training.runpod_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-19 14:50:08,055 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-19 14:50:08,058 - app.training.runpod_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-19 14:50:08,060 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-19 14:50:08,061 - app.training.runpod_trainer - INFO - Training output: raise ValueError(
2025-10-19 14:50:08,062 - app.training.runpod_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-19 14:50:08,065 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 14:50:07] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-19 14:50:08,067 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 4.5154, 'train_samples_per_second': 11.959, 'train_steps_per_second': 1.993, 'train_loss': 1.5063543319702148, 'epoch': 3.0}
2025-10-19 14:50:08,068 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 14:50:08,070 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 14:50:08,072 - app.training.runpod_trainer - INFO - Training output: Final training loss: 1.5064
2025-10-19 14:50:08,073 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 14:50:08,075 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 14:50:08,076 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.000240 kg CO2
2025-10-19 14:50:08,077 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 14:50:08,078 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 14:50:09,485 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 14:50:09,622 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 14:50:09,777 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 14:50:10,008 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 14:50:10,232 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 14:50:10,440 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 14:50:11,392 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 14:50:11,579 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 14:50:11,841 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 14:50:12,054 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 14:50:13,536 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 14:50:13,738 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 14:50:13,740 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945
2025-10-19 14:50:13,741 - app.training.runpod_trainer - INFO - Training completed successfully for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945
2025-10-19 14:50:13,742 - app.training.gpu_queue_manager - INFO - Training completed for job b98889a1-acfe-4ae6-b7a1-cd68b2edd8a4_20251019_144945
2025-10-19 14:50:13,759 - app.training.gpu_queue_manager - INFO - Marked runpod instance runpod-gpu-20251019141910 as idle for potential reuse
2025-10-19 14:58:05,083 - app.training.carbon_tracker - INFO - Started carbon tracking for understudy_e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7
2025-10-19 14:58:05,100 - app.training.trainer - INFO - Prepared dataset with 100 examples
2025-10-19 14:58:05,127 - app.training.trainer - INFO - Loading base model meta-llama/Llama-3.2-1B
2025-10-19 14:59:18,179 - app.training.trainer - INFO - Starting training...
2025-10-19 15:06:31,242 - app.main - INFO - Starting Understudy API...
2025-10-19 15:06:31,267 - app.main - INFO - Database initialized
2025-10-19 15:06:31,336 - app.main - INFO - Initializing GPU training queue...
2025-10-19 15:06:31,337 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 15:06:31,350 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 15:06:31,351 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 15:06:31,352 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 15:06:31,352 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 15:06:31,353 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 15:06:31,491 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 15:06:31,494 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 15:06:32,071 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 15:06:32,083 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 15:06:32,548 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 15:06:32,555 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 15:06:32,561 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 15:06:32,563 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 15:09:54,970 - app.main - INFO - Starting Understudy API...
2025-10-19 15:09:54,995 - app.main - INFO - Database initialized
2025-10-19 15:09:54,996 - app.main - INFO - Initializing GPU training queue...
2025-10-19 15:09:54,997 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 15:09:55,005 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 15:09:55,006 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 15:09:55,007 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 15:09:55,008 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 15:09:55,009 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 15:09:55,085 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 15:09:55,089 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 15:09:55,336 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 15:09:55,337 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 15:09:56,026 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 15:09:56,027 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 15:09:56,028 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 15:09:56,029 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 15:10:04,999 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 15:10:05,674 - app.training.gpu_queue_manager - INFO - Checking 1 existing RunPod pods for reuse eligibility
2025-10-19 15:10:12,708 - app.training.gpu_queue_manager - INFO - Found existing RunPod pod: runpod-gpu-20251019141910 (vsfok4a8a66mp1)
2025-10-19 15:10:12,713 - app.training.gpu_queue_manager - INFO - Discovered 1 existing RunPod pods available for reuse
2025-10-19 15:10:12,725 - app.main - INFO - Cloud GPU training system ready
2025-10-19 15:10:22,843 - app.training.gpu_queue_manager - INFO - Training job e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022 added to queue with priority 0
2025-10-19 15:10:33,271 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 15:10:33,273 - app.training.gpu_queue_manager - INFO - Checking for reusable RunPod pods among 1 active VMs
2025-10-19 15:10:33,275 - app.training.gpu_queue_manager - INFO - Reusing RunPod pod vsfok4a8a66mp1 (runpod-gpu-20251019141910)
2025-10-19 15:10:33,277 - app.training.gpu_queue_manager - INFO - Starting training for job e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022 on runpod runpod-gpu-20251019141910
2025-10-19 15:10:33,278 - app.training.runpod_trainer - INFO - Starting training execution on pod vsfok4a8a66mp1
2025-10-19 15:10:33,279 - app.training.runpod_trainer - INFO - Generated training script for RunPod
2025-10-19 15:10:33,280 - app.training.runpod_trainer - INFO - Attempting SSH connection to 103.196.86.192:14801 (attempt 1/10)
2025-10-19 15:10:33,282 - app.training.runpod_trainer - INFO - Using SSH private key from /app/keys/runpod_ssh_key
2025-10-19 15:10:33,353 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.9p1)
2025-10-19 15:10:33,531 - paramiko.transport - INFO - Authentication (publickey) successful!
2025-10-19 15:10:33,532 - app.training.runpod_trainer - INFO - SSH connection established to 103.196.86.192:14801
2025-10-19 15:10:33,756 - paramiko.transport.sftp - INFO - [chan 1] Opened sftp connection (server version 3)
2025-10-19 15:10:34,013 - paramiko.transport.sftp - INFO - [chan 1] sftp session closed.
2025-10-19 15:10:34,017 - app.training.runpod_trainer - INFO - Installing dependencies on RunPod...
2025-10-19 15:10:37,002 - app.training.runpod_trainer - INFO - Starting training...
2025-10-19 15:10:40,681 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 15:10:40] Multiple instances of codecarbon are allowed to run at the same time.
2025-10-19 15:10:40,728 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:40] [setup] RAM Tracking...
2025-10-19 15:10:40,731 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:40] [setup] CPU Tracking...
2025-10-19 15:10:41,898 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 15:10:41] No CPU tracking mode found. Falling back on estimation based on TDP for CPU.
2025-10-19 15:10:41,901 - app.training.runpod_trainer - INFO - Training output: Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU
2025-10-19 15:10:41,903 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:10:41,905 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41] CPU Model on constant consumption mode: AMD EPYC 75F3 32-Core Processor
2025-10-19 15:10:41,908 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 15:10:41] No CPU tracking mode found. Falling back on CPU load mode.
2025-10-19 15:10:41,910 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41] [setup] GPU Tracking...
2025-10-19 15:10:41,912 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41] Tracking Nvidia GPU via pynvml
2025-10-19 15:10:41,914 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41] The below tracking methods have been set up:
2025-10-19 15:10:41,916 - app.training.runpod_trainer - INFO - Training output: RAM Tracking Method: RAM power estimation model
2025-10-19 15:10:41,918 - app.training.runpod_trainer - INFO - Training output: CPU Tracking Method: cpu_load
2025-10-19 15:10:41,920 - app.training.runpod_trainer - INFO - Training output: GPU Tracking Method: pynvml
2025-10-19 15:10:41,922 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:10:41,925 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41] >>> Tracker's metadata:
2025-10-19 15:10:41,928 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   Platform system: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
2025-10-19 15:10:41,929 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   Python version: 3.10.12
2025-10-19 15:10:41,930 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   CodeCarbon version: 3.0.7
2025-10-19 15:10:41,932 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   Available RAM : 503.700 GB
2025-10-19 15:10:41,934 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   CPU count: 128 thread(s) in 2 physical CPU(s)
2025-10-19 15:10:41,936 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   CPU model: AMD EPYC 75F3 32-Core Processor
2025-10-19 15:10:41,937 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   GPU count: 1
2025-10-19 15:10:41,938 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:41]   GPU model: 1 x NVIDIA GeForce RTX 4090
2025-10-19 15:10:45,049 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:10:45] Emissions data (if any) will be saved to file /workspace/training/e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022/emissions.csv
2025-10-19 15:10:46,073 - app.training.runpod_trainer - INFO - Training output: `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-19 15:10:48,621 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 15:10:48,626 - app.training.runpod_trainer - INFO - Training output: Starting training job: e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022
2025-10-19 15:10:48,628 - app.training.runpod_trainer - INFO - Training output: Model: meta-llama/Llama-3.2-1B
2025-10-19 15:10:48,630 - app.training.runpod_trainer - INFO - Training output: Device: NVIDIA GeForce RTX 4090
2025-10-19 15:10:48,632 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 15:10:48,633 - app.training.runpod_trainer - INFO - Training output: Loaded 320 training examples
2025-10-19 15:10:48,635 - app.training.runpod_trainer - INFO - Training output: Loading tokenizer...
2025-10-19 15:10:48,638 - app.training.runpod_trainer - INFO - Training output: Loading base model...
2025-10-19 15:10:48,639 - app.training.runpod_trainer - INFO - Training output: Model loaded: LlamaForCausalLM(
2025-10-19 15:10:48,641 - app.training.runpod_trainer - INFO - Training output: (model): LlamaModel(
2025-10-19 15:10:48,642 - app.training.runpod_trainer - INFO - Training output: (embed_tokens): Embedding(128256, 2048)
2025-10-19 15:10:48,643 - app.training.runpod_trainer - INFO - Training output: (layers): ModuleList(
2025-10-19 15:10:48,646 - app.training.runpod_trainer - INFO - Training output: (0-15): 16 x LlamaDecoderLayer(
2025-10-19 15:10:48,647 - app.training.runpod_trainer - INFO - Training output: (self_attn): LlamaAttention(
2025-10-19 15:10:48,649 - app.training.runpod_trainer - INFO - Training output: (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 15:10:48,651 - app.training.runpod_trainer - INFO - Training output: (k_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 15:10:48,652 - app.training.runpod_trainer - INFO - Training output: (v_proj): Linear(in_features=2048, out_features=512, bias=False)
2025-10-19 15:10:48,653 - app.training.runpod_trainer - INFO - Training output: (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
2025-10-19 15:10:48,654 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,655 - app.training.runpod_trainer - INFO - Training output: (mlp): LlamaMLP(
2025-10-19 15:10:48,656 - app.training.runpod_trainer - INFO - Training output: (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 15:10:48,658 - app.training.runpod_trainer - INFO - Training output: (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
2025-10-19 15:10:48,659 - app.training.runpod_trainer - INFO - Training output: (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
2025-10-19 15:10:48,660 - app.training.runpod_trainer - INFO - Training output: (act_fn): SiLUActivation()
2025-10-19 15:10:48,661 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,662 - app.training.runpod_trainer - INFO - Training output: (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 15:10:48,663 - app.training.runpod_trainer - INFO - Training output: (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 15:10:48,663 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,665 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,665 - app.training.runpod_trainer - INFO - Training output: (norm): LlamaRMSNorm((2048,), eps=1e-05)
2025-10-19 15:10:48,667 - app.training.runpod_trainer - INFO - Training output: (rotary_emb): LlamaRotaryEmbedding()
2025-10-19 15:10:48,668 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,669 - app.training.runpod_trainer - INFO - Training output: (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
2025-10-19 15:10:48,670 - app.training.runpod_trainer - INFO - Training output: )
2025-10-19 15:10:48,671 - app.training.runpod_trainer - INFO - Training output: Configuring LoRA...
2025-10-19 15:10:48,672 - app.training.runpod_trainer - INFO - Training output: trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039
2025-10-19 15:10:48,672 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,673 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,674 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,675 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,676 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,677 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,678 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,679 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,680 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,681 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,682 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,683 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,683 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,685 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,686 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,686 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,687 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,688 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,689 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,690 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,691 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,692 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,693 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,694 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,694 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,695 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,696 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,697 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,698 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,699 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,700 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,701 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,702 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,702 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,703 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,704 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,705 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,706 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,707 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,708 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,709 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,709 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,710 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,711 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,712 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,713 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,713 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,714 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,715 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,716 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,717 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,718 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,718 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,719 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,720 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,721 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,722 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,723 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,724 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,725 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,726 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,727 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,728 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,729 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,729 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,730 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,731 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,732 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,733 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,734 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,735 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,736 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,737 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,737 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,738 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,739 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,739 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,740 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,741 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,743 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,744 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,745 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,746 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,747 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,747 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,748 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,749 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,750 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,751 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,752 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,753 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,754 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,754 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,755 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,756 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,757 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,758 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,759 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,760 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,760 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,761 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,762 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,763 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,764 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,764 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,765 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,766 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,767 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,768 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,769 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,770 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,771 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,771 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,772 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,773 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,775 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,776 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,776 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,777 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,778 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,779 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,779 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,781 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,781 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,782 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,783 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,784 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,785 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,786 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,787 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,788 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,788 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,789 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,790 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,791 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,792 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,793 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,794 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,795 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,796 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,797 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,798 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,799 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,800 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,802 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,802 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,803 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,804 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,805 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,806 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,807 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,808 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,809 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,810 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,811 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,812 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,813 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,814 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,814 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,815 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,816 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,817 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,818 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,819 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,820 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,821 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,822 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,823 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,824 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,825 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,826 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,827 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,828 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,829 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,829 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,830 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,831 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,832 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,833 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,834 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,835 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,836 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,837 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,838 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,839 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,840 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,840 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,842 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,843 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,844 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,844 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,845 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,846 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,847 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,847 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,849 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,850 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,851 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,851 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,852 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,853 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,854 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,855 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,856 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,857 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,858 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,859 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,860 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,861 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,862 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,863 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,864 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,865 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,866 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,867 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,868 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,869 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,869 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,870 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,871 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,872 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,873 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,874 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, requires_grad: True
2025-10-19 15:10:48,875 - app.training.runpod_trainer - INFO - Training output: LoRA parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, requires_grad: True
2025-10-19 15:10:48,876 - app.training.runpod_trainer - INFO - Training output: Total trainable parameters: 11272192
2025-10-19 15:10:48,877 - app.training.runpod_trainer - INFO - Training output: LoRA parameters: 11272192
2025-10-19 15:10:48,878 - app.training.runpod_trainer - INFO - Training output: Preparing dataset...
2025-10-19 15:10:48,879 - app.training.runpod_trainer - INFO - Training output: Map:   0%|          | 0/320 [00:00<?, ? examples/s]Map: 100%|| 320/320 [00:00<00:00, 5823.32 examples/s]
2025-10-19 15:10:48,880 - app.training.runpod_trainer - INFO - Training output: /workspace/training/e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022/train.py:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-10-19 15:10:48,881 - app.training.runpod_trainer - INFO - Training output: trainer = Trainer(
2025-10-19 15:10:48,882 - app.training.runpod_trainer - INFO - Training output: The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-19 15:10:48,883 - app.training.runpod_trainer - INFO - Training output: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.
2025-10-19 15:10:49,148 - app.training.runpod_trainer - INFO - Training output: Train samples: 288, Eval samples: 32
2025-10-19 15:10:49,151 - app.training.runpod_trainer - INFO - Training output: Starting training...
2025-10-19 15:10:49,153 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 15:10:49,177 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/108 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
2025-10-19 15:11:00,533 - app.training.runpod_trainer - INFO - Training output: 1%|          | 1/108 [00:00<01:33,  1.14it/s]  2%|         | 2/108 [00:01<01:08,  1.55it/s]  3%|         | 3/108 [00:01<01:00,  1.74it/s]  4%|         | 4/108 [00:02<00:55,  1.86it/s]  5%|         | 5/108 [00:02<00:53,  1.94it/s]  6%|         | 6/108 [00:03<00:51,  2.00it/s]  6%|         | 7/108 [00:03<00:49,  2.03it/s]  7%|         | 8/108 [00:04<00:48,  2.04it/s]  8%|         | 9/108 [00:04<00:48,  2.06it/s]  9%|         | 10/108 [00:05<00:47,  2.07it/s]                                                  9%|         | 10/108 [00:05<00:47,  2.07it/s] 10%|         | 11/108 [00:05<00:46,  2.10it/s] 11%|         | 12/108 [00:06<00:46,  2.08it/s] 12%|        | 13/108 [00:06<00:45,  2.09it/s] 13%|        | 14/108 [00:07<00:44,  2.09it/s] 14%|        | 15/108 [00:07<00:44,  2.08it/s] 15%|        | 16/108 [00:08<00:43,  2.09it/s] 16%|        | 17/108 [00:08<00:43,  2.10it/s] 17%|        | 18/108 [00:09<00:42,  2.10it/s] 18%|        | 19/108 [00:09<00:42,  2.08it/s] 19%|        | 20/108 [00:09<00:42,  2.05it/s]                                                 19%|        | 20/108 [00:09<00:42,  2.05it/s] 19%|        | 21/108 [00:10<00:42,  2.03it/s] 20%|        | 22/108 [00:10<00:42,  2.04it/s][codecarbon INFO @ 15:11:00] Energy consumed for RAM : 0.000301 kWh. RAM Power : 70.0 W
2025-10-19 15:11:01,038 - app.training.runpod_trainer - INFO - Training output: 21%|       | 23/108 [00:11<00:41,  2.06it/s][codecarbon INFO @ 15:11:01] Delta energy consumed for CPU with cpu_load : 0.000241 kWh, power : 56.03061191840001 W
2025-10-19 15:11:01,041 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:01] Energy consumed for All CPU : 0.000241 kWh
2025-10-19 15:11:01,043 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:01] Energy consumed for all GPUs : 0.000894 kWh. Total GPU Power : 201.0442507790121 W
2025-10-19 15:11:01,045 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:01] 0.001437 kWh of electricity used since the beginning.
2025-10-19 15:11:13,623 - app.training.runpod_trainer - INFO - Training output: 22%|       | 24/108 [00:11<00:40,  2.07it/s] 23%|       | 25/108 [00:12<00:39,  2.08it/s] 24%|       | 26/108 [00:12<00:39,  2.08it/s] 25%|       | 27/108 [00:13<00:38,  2.09it/s] 26%|       | 28/108 [00:13<00:38,  2.09it/s] 27%|       | 29/108 [00:14<00:37,  2.09it/s] 28%|       | 30/108 [00:14<00:37,  2.07it/s]                                                 28%|       | 30/108 [00:14<00:37,  2.07it/s] 29%|       | 31/108 [00:15<00:37,  2.07it/s] 30%|       | 32/108 [00:15<00:36,  2.08it/s] 31%|       | 33/108 [00:16<00:35,  2.09it/s] 31%|      | 34/108 [00:16<00:35,  2.09it/s] 32%|      | 35/108 [00:17<00:34,  2.10it/s] 33%|      | 36/108 [00:17<00:34,  2.10it/s] 34%|      | 37/108 [00:18<00:33,  2.10it/s] 35%|      | 38/108 [00:18<00:33,  2.10it/s] 36%|      | 39/108 [00:19<00:33,  2.09it/s] 37%|      | 40/108 [00:19<00:32,  2.09it/s]                                                 37%|      | 40/108 [00:19<00:32,  2.09it/s] 38%|      | 41/108 [00:20<00:32,  2.09it/s] 39%|      | 42/108 [00:20<00:31,  2.09it/s] 40%|      | 43/108 [00:21<00:31,  2.10it/s] 41%|      | 44/108 [00:21<00:30,  2.10it/s] 42%|     | 45/108 [00:21<00:29,  2.10it/s] 43%|     | 46/108 [00:22<00:29,  2.10it/s] 44%|     | 47/108 [00:22<00:29,  2.10it/s] 44%|     | 48/108 [00:23<00:28,  2.08it/s] 45%|     | 49/108 [00:23<00:28,  2.09it/s] 46%|     | 50/108 [00:24<00:27,  2.09it/s]                                                 46%|     | 50/108 [00:24<00:27,  2.09it/s]{'loss': 2.1869, 'grad_norm': 3.0990092754364014, 'learning_rate': 0.00016363636363636366, 'epoch': 0.28}
2025-10-19 15:11:13,628 - app.training.runpod_trainer - INFO - Training output: {'loss': 1.6583, 'grad_norm': 2.4115710258483887, 'learning_rate': 0.00019744105246469263, 'epoch': 0.56}
2025-10-19 15:11:13,630 - app.training.runpod_trainer - INFO - Training output: {'loss': 1.5016, 'grad_norm': 2.5886406898498535, 'learning_rate': 0.00018522168236559695, 'epoch': 0.83}
2025-10-19 15:11:13,631 - app.training.runpod_trainer - INFO - Training output: {'loss': 1.2018, 'grad_norm': 2.125213146209717, 'learning_rate': 0.000164140821963114, 'epoch': 1.11}
2025-10-19 15:11:13,633 - app.training.runpod_trainer - INFO - Training output: {'loss': 1.0143, 'grad_norm': 2.507878303527832, 'learning_rate': 0.00013639049369634876, 'epoch': 1.39}
2025-10-19 15:11:13,635 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:11:13,692 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/8 [00:00<?, ?it/s][A
2025-10-19 15:11:13,883 - app.training.runpod_trainer - INFO - Training output: 38%|      | 3/8 [00:00<00:00, 24.48it/s][A
2025-10-19 15:11:14,009 - app.training.runpod_trainer - INFO - Training output: 75%|  | 6/8 [00:00<00:00, 18.66it/s][A
2025-10-19 15:11:14,036 - app.training.runpod_trainer - INFO - Training output: 100%|| 8/8 [00:00<00:00, 17.54it/s][A
2025-10-19 15:11:14,038 - app.training.runpod_trainer - INFO - Training output: [A 46%|     | 50/108 [00:24<00:27,  2.09it/s]
2025-10-19 15:11:14,040 - app.training.runpod_trainer - INFO - Training output: 100%|| 8/8 [00:00<00:00, 17.54it/s][A
2025-10-19 15:11:15,533 - app.training.runpod_trainer - INFO - Training output: [A 47%|     | 51/108 [00:25<00:36,  1.58it/s] 48%|     | 52/108 [00:25<00:32,  1.70it/s] 49%|     | 53/108 [00:26<00:30,  1.81it/s][codecarbon INFO @ 15:11:15] Energy consumed for RAM : 0.000583 kWh. RAM Power : 70.0 W
2025-10-19 15:11:16,035 - app.training.runpod_trainer - INFO - Training output: 50%|     | 54/108 [00:26<00:28,  1.88it/s][codecarbon INFO @ 15:11:16] Delta energy consumed for CPU with cpu_load : 0.000226 kWh, power : 56.00044846550001 W
2025-10-19 15:11:16,039 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:16] Energy consumed for All CPU : 0.000467 kWh
2025-10-19 15:11:16,041 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:16] Energy consumed for all GPUs : 0.002013 kWh. Total GPU Power : 268.50214972729015 W
2025-10-19 15:11:16,043 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:16] 0.003063 kWh of electricity used since the beginning.
2025-10-19 15:11:30,619 - app.training.runpod_trainer - INFO - Training output: 51%|     | 55/108 [00:27<00:27,  1.94it/s] 52%|    | 56/108 [00:27<00:26,  1.99it/s] 53%|    | 57/108 [00:28<00:25,  2.01it/s] 54%|    | 58/108 [00:28<00:24,  2.03it/s] 55%|    | 59/108 [00:29<00:23,  2.05it/s] 56%|    | 60/108 [00:29<00:23,  2.06it/s]                                                 56%|    | 60/108 [00:29<00:23,  2.06it/s] 56%|    | 61/108 [00:30<00:22,  2.08it/s] 57%|    | 62/108 [00:30<00:22,  2.08it/s] 58%|    | 63/108 [00:31<00:21,  2.07it/s] 59%|    | 64/108 [00:31<00:21,  2.08it/s] 60%|    | 65/108 [00:32<00:20,  2.09it/s] 61%|    | 66/108 [00:32<00:20,  2.09it/s] 62%|   | 67/108 [00:33<00:19,  2.10it/s] 63%|   | 68/108 [00:33<00:19,  2.08it/s] 64%|   | 69/108 [00:33<00:18,  2.09it/s] 65%|   | 70/108 [00:34<00:18,  2.10it/s]                                                 65%|   | 70/108 [00:34<00:18,  2.10it/s] 66%|   | 71/108 [00:34<00:17,  2.10it/s] 67%|   | 72/108 [00:35<00:17,  2.10it/s] 68%|   | 73/108 [00:35<00:16,  2.10it/s] 69%|   | 74/108 [00:36<00:16,  2.10it/s] 69%|   | 75/108 [00:36<00:15,  2.10it/s] 70%|   | 76/108 [00:37<00:15,  2.10it/s] 71%|  | 77/108 [00:37<00:14,  2.10it/s] 72%|  | 78/108 [00:38<00:14,  2.10it/s] 73%|  | 79/108 [00:38<00:13,  2.10it/s] 74%|  | 80/108 [00:39<00:13,  2.10it/s]                                                 74%|  | 80/108 [00:39<00:13,  2.10it/s] 75%|  | 81/108 [00:39<00:12,  2.10it/s] 76%|  | 82/108 [00:40<00:12,  2.10it/s] 77%|  | 83/108 [00:40<00:11,  2.09it/s] 78%|  | 84/108 [00:41<00:11,  2.07it/s][codecarbon INFO @ 15:11:30] Energy consumed for RAM : 0.000865 kWh. RAM Power : 70.0 W
2025-10-19 15:11:31,132 - app.training.runpod_trainer - INFO - Training output: 79%|  | 85/108 [00:41<00:11,  2.08it/s][codecarbon INFO @ 15:11:31] Delta energy consumed for CPU with cpu_load : 0.000226 kWh, power : 56.00175899150001 W
2025-10-19 15:11:31,135 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:31] Energy consumed for All CPU : 0.000692 kWh
2025-10-19 15:11:31,137 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:31] Energy consumed for all GPUs : 0.003131 kWh. Total GPU Power : 268.3545626785874 W
2025-10-19 15:11:31,139 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:31] 0.004688 kWh of electricity used since the beginning.
2025-10-19 15:11:37,918 - app.training.runpod_trainer - INFO - Training output: 80%|  | 86/108 [00:42<00:10,  2.09it/s] 81%|  | 87/108 [00:42<00:10,  2.09it/s] 81%| | 88/108 [00:43<00:09,  2.08it/s] 82%| | 89/108 [00:43<00:09,  2.09it/s] 83%| | 90/108 [00:43<00:08,  2.10it/s]                                                 83%| | 90/108 [00:43<00:08,  2.10it/s] 84%| | 91/108 [00:44<00:08,  2.10it/s] 85%| | 92/108 [00:44<00:07,  2.11it/s] 86%| | 93/108 [00:45<00:07,  2.11it/s] 87%| | 94/108 [00:45<00:06,  2.11it/s] 88%| | 95/108 [00:46<00:06,  2.12it/s] 89%| | 96/108 [00:46<00:05,  2.12it/s] 90%| | 97/108 [00:47<00:05,  2.11it/s] 91%| | 98/108 [00:47<00:04,  2.11it/s] 92%|| 99/108 [00:48<00:04,  2.11it/s] 93%|| 100/108 [00:48<00:03,  2.11it/s]                                                  93%|| 100/108 [00:48<00:03,  2.11it/s]{'eval_loss': 1.2028077840805054, 'eval_runtime': 0.5058, 'eval_samples_per_second': 63.261, 'eval_steps_per_second': 15.815, 'epoch': 1.39}
2025-10-19 15:11:37,924 - app.training.runpod_trainer - INFO - Training output: {'loss': 1.0011, 'grad_norm': 2.2233598232269287, 'learning_rate': 0.00010485622221144484, 'epoch': 1.67}
2025-10-19 15:11:37,927 - app.training.runpod_trainer - INFO - Training output: {'loss': 0.9441, 'grad_norm': 2.415273904800415, 'learning_rate': 7.281699277636572e-05, 'epoch': 1.94}
2025-10-19 15:11:37,929 - app.training.runpod_trainer - INFO - Training output: {'loss': 0.7143, 'grad_norm': 1.8496350049972534, 'learning_rate': 4.360429701490934e-05, 'epoch': 2.22}
2025-10-19 15:11:37,931 - app.training.runpod_trainer - INFO - Training output: {'loss': 0.6755, 'grad_norm': 2.4280827045440674, 'learning_rate': 2.025571894372794e-05, 'epoch': 2.5}
2025-10-19 15:11:37,933 - app.training.runpod_trainer - INFO - Training output: {'loss': 0.7137, 'grad_norm': 2.5975894927978516, 'learning_rate': 5.199082004372957e-06, 'epoch': 2.78}
2025-10-19 15:11:37,935 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:11:38,042 - app.training.runpod_trainer - INFO - Training output: 0%|          | 0/8 [00:00<?, ?it/s][A
2025-10-19 15:11:38,228 - app.training.runpod_trainer - INFO - Training output: 38%|      | 3/8 [00:00<00:00, 24.17it/s][A
2025-10-19 15:11:38,354 - app.training.runpod_trainer - INFO - Training output: 75%|  | 6/8 [00:00<00:00, 18.56it/s][A
2025-10-19 15:11:38,387 - app.training.runpod_trainer - INFO - Training output: 100%|| 8/8 [00:00<00:00, 17.64it/s][A
2025-10-19 15:11:38,389 - app.training.runpod_trainer - INFO - Training output: [A 93%|| 100/108 [00:49<00:03,  2.11it/s]
2025-10-19 15:11:38,391 - app.training.runpod_trainer - INFO - Training output: 100%|| 8/8 [00:00<00:00, 17.64it/s][A
2025-10-19 15:11:38,433 - app.training.runpod_trainer - INFO - Training output: [A/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4ffaa-536247b85799edeb37d7cbbf;528bbec8-e3b5-4fb7-98c7-d0a48ce5bcce)
2025-10-19 15:11:38,435 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:11:38,437 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 15:11:38,438 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 15:11:38,439 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:38,441 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 15:11:38,442 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:42,912 - app.training.runpod_trainer - INFO - Training output: 94%|| 101/108 [00:50<00:05,  1.19it/s] 94%|| 102/108 [00:50<00:04,  1.37it/s] 95%|| 103/108 [00:51<00:03,  1.54it/s] 96%|| 104/108 [00:51<00:02,  1.67it/s] 97%|| 105/108 [00:52<00:01,  1.79it/s] 98%|| 106/108 [00:52<00:01,  1.87it/s] 99%|| 107/108 [00:53<00:00,  1.94it/s]100%|| 108/108 [00:53<00:00,  1.99it/s]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4ffae-6f0bd8ce1f2e932765f88e7d;e1182b28-33c3-47c3-b848-e59aac7df7cc)
2025-10-19 15:11:42,915 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:11:42,917 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 15:11:42,919 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 15:11:42,921 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:42,924 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 15:11:42,926 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:43,622 - app.training.runpod_trainer - INFO - Training output: 100%|| 108/108 [00:54<00:00,  1.99it/s]100%|| 108/108 [00:54<00:00,  1.99it/s]
2025-10-19 15:11:43,623 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-68f4ffaf-2850db0b5761c89936d3b582;404d6e09-e7b4-4951-9452-fb29859806ef)
2025-10-19 15:11:43,624 - app.training.runpod_trainer - INFO - Training output: 
2025-10-19 15:11:43,626 - app.training.runpod_trainer - INFO - Training output: Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.
2025-10-19 15:11:43,627 - app.training.runpod_trainer - INFO - Training output: Access to model meta-llama/Llama-3.2-1B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-1B.
2025-10-19 15:11:43,628 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:43,629 - app.training.runpod_trainer - INFO - Training output: /usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in meta-llama/Llama-3.2-1B - will assume that the vocabulary was not modified.
2025-10-19 15:11:43,630 - app.training.runpod_trainer - INFO - Training output: warnings.warn(
2025-10-19 15:11:44,339 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:44] Energy consumed for RAM : 0.001123 kWh. RAM Power : 70.0 W
2025-10-19 15:11:44,804 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:44] Delta energy consumed for CPU with cpu_load : 0.000206 kWh, power : 56.000614275200014 W
2025-10-19 15:11:44,807 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:44] Energy consumed for All CPU : 0.000899 kWh
2025-10-19 15:11:44,809 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:44] Energy consumed for all GPUs : 0.004031 kWh. Total GPU Power : 235.55160170611686 W
2025-10-19 15:11:44,811 - app.training.runpod_trainer - INFO - Training output: [codecarbon INFO @ 15:11:44] 0.006053 kWh of electricity used since the beginning.
2025-10-19 15:11:44,814 - app.training.runpod_trainer - INFO - Training output: [codecarbon ERROR @ 15:11:44] Region:  not found for Country with ISO CODE : USA
2025-10-19 15:11:44,816 - app.training.runpod_trainer - INFO - Training output: Traceback (most recent call last):
2025-10-19 15:11:44,818 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 142, in get_private_infra_emissions
2025-10-19 15:11:44,820 - app.training.runpod_trainer - INFO - Training output: return self.get_region_emissions(energy, geo)
2025-10-19 15:11:44,821 - app.training.runpod_trainer - INFO - Training output: File "/usr/local/lib/python3.10/dist-packages/codecarbon/core/emissions.py", line 168, in get_region_emissions
2025-10-19 15:11:44,824 - app.training.runpod_trainer - INFO - Training output: raise ValueError(
2025-10-19 15:11:44,826 - app.training.runpod_trainer - INFO - Training output: ValueError: Region:  not found for Country with ISO CODE : USA
2025-10-19 15:11:44,827 - app.training.runpod_trainer - INFO - Training output: [codecarbon WARNING @ 15:11:44] Regional emissions retrieval failed. Falling back on country emissions.
2025-10-19 15:11:44,828 - app.training.runpod_trainer - INFO - Training output: {'eval_loss': 1.209781289100647, 'eval_runtime': 0.5057, 'eval_samples_per_second': 63.276, 'eval_steps_per_second': 15.819, 'epoch': 2.78}
2025-10-19 15:11:44,830 - app.training.runpod_trainer - INFO - Training output: {'train_runtime': 54.3921, 'train_samples_per_second': 15.885, 'train_steps_per_second': 1.986, 'train_loss': 1.123677924827293, 'epoch': 3.0}
2025-10-19 15:11:44,831 - app.training.runpod_trainer - INFO - Training output: --------------------------------------------------
2025-10-19 15:11:44,832 - app.training.runpod_trainer - INFO - Training output: Training completed!
2025-10-19 15:11:44,833 - app.training.runpod_trainer - INFO - Training output: Final training loss: 1.1237
2025-10-19 15:11:44,835 - app.training.runpod_trainer - INFO - Training output: Saving model...
2025-10-19 15:11:44,836 - app.training.runpod_trainer - INFO - Training output: Model saved successfully!
2025-10-19 15:11:44,837 - app.training.runpod_trainer - INFO - Training output: Carbon emissions: 0.002236 kg CO2
2025-10-19 15:11:44,838 - app.training.runpod_trainer - INFO - Training output: ==================================================
2025-10-19 15:11:44,839 - app.training.runpod_trainer - INFO - Training output: Training job completed successfully!
2025-10-19 15:11:46,287 - app.training.runpod_trainer - INFO - Downloading trained model...
2025-10-19 15:11:46,388 - paramiko.transport.sftp - INFO - [chan 4] Opened sftp connection (server version 3)
2025-10-19 15:11:46,509 - app.training.runpod_trainer - INFO - Downloading carbon_emissions.json...
2025-10-19 15:11:46,699 - app.training.runpod_trainer - INFO - Downloading training_metrics.json...
2025-10-19 15:11:46,886 - app.training.runpod_trainer - INFO - Downloading training_args.bin...
2025-10-19 15:11:47,114 - app.training.runpod_trainer - INFO - Downloading tokenizer.json...
2025-10-19 15:11:49,076 - app.training.runpod_trainer - INFO - Downloading special_tokens_map.json...
2025-10-19 15:11:49,256 - app.training.runpod_trainer - INFO - Downloading tokenizer_config.json...
2025-10-19 15:11:49,470 - app.training.runpod_trainer - INFO - Downloading adapter_config.json...
2025-10-19 15:11:49,660 - app.training.runpod_trainer - INFO - Downloading adapter_model.safetensors...
2025-10-19 15:11:51,162 - app.training.runpod_trainer - INFO - Downloading README.md...
2025-10-19 15:11:51,345 - paramiko.transport.sftp - INFO - [chan 4] sftp session closed.
2025-10-19 15:11:51,346 - app.training.runpod_trainer - INFO - Model downloaded to /app/models/e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022
2025-10-19 15:11:51,347 - app.training.runpod_trainer - INFO - Training completed successfully for job e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022
2025-10-19 15:11:51,349 - app.training.gpu_queue_manager - INFO - Training completed for job e1ac4e8f-e27f-4b7d-b236-dd5780b3e4e7_20251019_151022
2025-10-19 15:11:51,356 - app.training.gpu_queue_manager - INFO - Marked runpod instance runpod-gpu-20251019141910 as idle for potential reuse
2025-10-19 15:12:32,905 - app.main - INFO - Shutting down Understudy API...
2025-10-19 15:20:34,979 - app.main - INFO - Starting Understudy API...
2025-10-19 15:20:35,002 - app.main - INFO - Database initialized
2025-10-19 15:20:35,003 - app.main - INFO - Initializing GPU training queue...
2025-10-19 15:20:35,003 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 15:20:35,011 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 15:20:35,013 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 15:20:35,014 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 15:20:35,015 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 15:20:35,015 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 15:20:35,088 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 15:20:35,091 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 15:20:35,318 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 15:20:35,321 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 15:20:35,899 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 15:20:35,907 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 15:20:35,914 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 15:20:35,916 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 15:20:39,736 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 15:20:39,745 - app.training.gpu_queue_manager - INFO - Checking 1 existing RunPod pods for reuse eligibility
2025-10-19 15:20:39,753 - app.training.gpu_queue_manager - INFO - Found existing RunPod pod: runpod-gpu-20251019141910 (vsfok4a8a66mp1)
2025-10-19 15:20:39,755 - app.training.gpu_queue_manager - INFO - Discovered 1 existing RunPod pods available for reuse
2025-10-19 15:20:39,757 - app.main - INFO - Cloud GPU training system ready
2025-10-19 15:26:58,325 - app.main - INFO - Shutting down Understudy API...
2025-10-19 15:27:09,202 - app.main - INFO - Starting Understudy API...
2025-10-19 15:27:09,222 - app.main - INFO - Database initialized
2025-10-19 15:27:09,223 - app.main - INFO - Initializing GPU training queue...
2025-10-19 15:27:09,223 - app.training.gpu_queue_manager - INFO - Starting GPU queue manager initialization...
2025-10-19 15:27:09,230 - app.training.gpu_queue_manager - INFO - Redis connection established for training queue
2025-10-19 15:27:09,231 - app.training.gpu_queue_manager - INFO - GPU training queue processor started
2025-10-19 15:27:09,232 - app.training.gpu_queue_manager - INFO - About to check Lambda instance reuse configuration...
2025-10-19 15:27:09,232 - app.training.gpu_queue_manager - INFO - Lambda instance reuse enabled: True
2025-10-19 15:27:09,233 - app.training.gpu_queue_manager - INFO - Checking for existing Lambda instances to reuse...
2025-10-19 15:27:09,301 - app.training.gpu_queue_manager - INFO - Setting up SSH key for Lambda instance reuse...
2025-10-19 15:27:09,304 - app.training.gpu_queue_manager - INFO - Starting training queue processor
2025-10-19 15:27:09,842 - app.training.lambda_cloud_trainer - INFO - SSH key 'understudy-key-v2' already exists in Lambda Cloud
2025-10-19 15:27:09,845 - app.training.lambda_cloud_trainer - INFO - Using existing private key from /app/keys/lambda_cloud_understudy-key-v2.pem
2025-10-19 15:27:10,564 - app.training.lambda_cloud_trainer - INFO - Found 0 existing Lambda Cloud instances
2025-10-19 15:27:10,568 - app.training.gpu_queue_manager - INFO - Checking 0 existing Lambda instances for reuse eligibility
2025-10-19 15:27:10,572 - app.training.gpu_queue_manager - INFO - RunPod pod reuse enabled: True
2025-10-19 15:27:10,575 - app.training.gpu_queue_manager - INFO - Checking for existing RunPod pods to reuse...
2025-10-19 15:27:10,949 - app.training.runpod_trainer - INFO - Found 1 existing RunPod instances
2025-10-19 15:27:10,952 - app.training.gpu_queue_manager - INFO - Checking 1 existing RunPod pods for reuse eligibility
2025-10-19 15:27:10,956 - app.training.gpu_queue_manager - INFO - Found existing RunPod pod: runpod-gpu-20251019141910 (vsfok4a8a66mp1)
2025-10-19 15:27:10,958 - app.training.gpu_queue_manager - INFO - Discovered 1 existing RunPod pods available for reuse
2025-10-19 15:27:10,959 - app.main - INFO - Cloud GPU training system ready
