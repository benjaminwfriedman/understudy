version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
      - "5678:5678"
    environment:
      - DATABASE_URL=sqlite+aiosqlite:///./data/understudy.db
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - HF_TOKEN={HF_TOKEN}
      - CARBON_TRACKING_ENABLED=true
      - LOG_LEVEL=INFO
      # RunPod GPU Training Configuration
      - RUNPOD_TRAINING_ENABLED=true
      - RUNPOD_POD_REUSE=false
      - RUNPOD_POD_IDLE_MINUTES=3
      - RUNPOD_POD_AUTO_SHUTDOWN=true
      - RUNPOD_API_KEY=${RUNPOD_API_KEY}
      - RUNPOD_GPU_TYPE=NVIDIA GeForce RTX 4090
      - RUNPOD_CONTAINER_IMAGE=runpod/pytorch:2.0.1-py3.10-cuda11.8.0-devel-ubuntu22.04
      - RUNPOD_DISK_SIZE=50
      - RUNPOD_SSH_PUBLIC_KEY="" ## set to the public key copied to clipboard after runpod_config.sh
      - RUNPOD_SSH_PRIVATE_KEY_PATH=/app/keys/{generated_key} ## Change the name to the key you create with runpod_config.sh
      # - GPU_TRAINING_PROVIDER=lambda
      # Redis for job queue (optional, falls back to in-memory)
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./checkpoints:/app/checkpoints
      - ./carbon_data:/app/carbon_data
      - ./logs:/app/logs
      - ./keys:/app/keys
      - ~/.azure:/home/appuser/.azure
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 48G  # Allocated for CPU training
        reservations:
          cpus: '4.0'
          memory: 32G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost"]
      interval: 30s
      timeout: 5s
      retries: 3

networks:
  default:
    name: understudy-network

volumes:
  data:
    driver: local
  models:
    driver: local
  checkpoints:
    driver: local
  carbon_data:
    driver: local
  logs:
    driver: local
  redis_data:
    driver: local